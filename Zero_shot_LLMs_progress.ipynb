{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e42629e4c0ea4c2989c1e19265de1379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ff7f26372b34ba7865b876c99d611a9",
              "IPY_MODEL_dacce8febb7e40d58fffc48634c18d16",
              "IPY_MODEL_fe1c728fc4554866b0546cc64a3f8c3f"
            ],
            "layout": "IPY_MODEL_1ec03ab812504f8990aecba183f937b2"
          }
        },
        "0ff7f26372b34ba7865b876c99d611a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a9341b926124553899b1380bfc4ddc2",
            "placeholder": "​",
            "style": "IPY_MODEL_bba4f58f8a7041bd846e45b6ee2adc04",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "dacce8febb7e40d58fffc48634c18d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50af6242b048484688b55452dbc8d9b3",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7aef99d92fd949898a738b6f2c350d70",
            "value": 481
          }
        },
        "fe1c728fc4554866b0546cc64a3f8c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b611b99d4134485bb15a786abd56556",
            "placeholder": "​",
            "style": "IPY_MODEL_626bbed881484563b2405affcd8c1634",
            "value": " 481/481 [00:00&lt;00:00, 27.3kB/s]"
          }
        },
        "1ec03ab812504f8990aecba183f937b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a9341b926124553899b1380bfc4ddc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bba4f58f8a7041bd846e45b6ee2adc04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50af6242b048484688b55452dbc8d9b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aef99d92fd949898a738b6f2c350d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b611b99d4134485bb15a786abd56556": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "626bbed881484563b2405affcd8c1634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4b70b8e03cd4f14820235299d4ecb49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f39d660b5a84890b46ee424c5191ba0",
              "IPY_MODEL_941e210f70a244df8b3f712de5badd3a",
              "IPY_MODEL_00a7a30921ac4b6999889be4aac4a980"
            ],
            "layout": "IPY_MODEL_fe54511ba8cc40c59754d0d7a14a08c5"
          }
        },
        "5f39d660b5a84890b46ee424c5191ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23662c4615d54b89a65eda69eb0b515c",
            "placeholder": "​",
            "style": "IPY_MODEL_f4b8d4a502e448c1b8f0e319b7970f05",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "941e210f70a244df8b3f712de5badd3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_911a18e21c1d450f827ae2e5a306d59a",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da2b13cca65b441bbe6fbd06b304ee57",
            "value": 898823
          }
        },
        "00a7a30921ac4b6999889be4aac4a980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eb46c060ab84f5f86a3f295251e5820",
            "placeholder": "​",
            "style": "IPY_MODEL_5a37894abc7c485bb8f441c1e3fb27be",
            "value": " 899k/899k [00:00&lt;00:00, 20.6MB/s]"
          }
        },
        "fe54511ba8cc40c59754d0d7a14a08c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23662c4615d54b89a65eda69eb0b515c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4b8d4a502e448c1b8f0e319b7970f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "911a18e21c1d450f827ae2e5a306d59a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da2b13cca65b441bbe6fbd06b304ee57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4eb46c060ab84f5f86a3f295251e5820": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a37894abc7c485bb8f441c1e3fb27be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a40615c899b24762b669a561932a0e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36771afbf54b4f6eaf07388ad6ec49a0",
              "IPY_MODEL_6f4792fde6f74650b47967d8061e304c",
              "IPY_MODEL_72088c66ecff4345b28a41262b68ab16"
            ],
            "layout": "IPY_MODEL_ac4f99eac3854db18a4e980dc5478bef"
          }
        },
        "36771afbf54b4f6eaf07388ad6ec49a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c906513543e648e589ebb3254ac4d250",
            "placeholder": "​",
            "style": "IPY_MODEL_d1a2f6435ec04f77a36fbd3570a27701",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "6f4792fde6f74650b47967d8061e304c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a80d50aefff4c98b739ca2cdd3a6a57",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0540e87ddb4649d0ab7d388fa3338426",
            "value": 456318
          }
        },
        "72088c66ecff4345b28a41262b68ab16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43f1534b16d4421395fb5e4330d7e961",
            "placeholder": "​",
            "style": "IPY_MODEL_7270fce7b2194be488d4c3678cba5fb1",
            "value": " 456k/456k [00:00&lt;00:00, 21.1MB/s]"
          }
        },
        "ac4f99eac3854db18a4e980dc5478bef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c906513543e648e589ebb3254ac4d250": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1a2f6435ec04f77a36fbd3570a27701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a80d50aefff4c98b739ca2cdd3a6a57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0540e87ddb4649d0ab7d388fa3338426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43f1534b16d4421395fb5e4330d7e961": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7270fce7b2194be488d4c3678cba5fb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2568bed565d41a3982e1ecdc8c1dd29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffb529a6b77c4f2e91f46f5142dd8d0e",
              "IPY_MODEL_4d7b855988c2460b84ab2ea2e5a10aaf",
              "IPY_MODEL_24ca0de4a2ba42c79c29aa9a04f0928f"
            ],
            "layout": "IPY_MODEL_bb827723b78643619181159645852102"
          }
        },
        "ffb529a6b77c4f2e91f46f5142dd8d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a97611ddadb4aae9b0a2ca8a6656bfa",
            "placeholder": "​",
            "style": "IPY_MODEL_6dcb60f0c1de43f18a010a50557e565c",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "4d7b855988c2460b84ab2ea2e5a10aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdedba24c2334bed9e07f802e794d249",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f19dc21214a4576a9b72d6d9cd48a93",
            "value": 1355863
          }
        },
        "24ca0de4a2ba42c79c29aa9a04f0928f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88f460c78dce43a0b1e6f90f22bbb0ac",
            "placeholder": "​",
            "style": "IPY_MODEL_5fcbdc37cc8344309a95a741a6afebbc",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 33.9MB/s]"
          }
        },
        "bb827723b78643619181159645852102": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a97611ddadb4aae9b0a2ca8a6656bfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dcb60f0c1de43f18a010a50557e565c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdedba24c2334bed9e07f802e794d249": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f19dc21214a4576a9b72d6d9cd48a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88f460c78dce43a0b1e6f90f22bbb0ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fcbdc37cc8344309a95a741a6afebbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca2182f72ac34bf3ba3e2c7947385f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc286bad36ee46fe8f7814a14acf17e5",
              "IPY_MODEL_8918536c112f467c9a2c8e1c86d054f0",
              "IPY_MODEL_90a6469f8f9d4dc99502e2102e8e8bd3"
            ],
            "layout": "IPY_MODEL_1088fbb56ee445a089addf9eb4b5a6bc"
          }
        },
        "cc286bad36ee46fe8f7814a14acf17e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_308517fe44c74e3d9fa1175729aa8ab3",
            "placeholder": "​",
            "style": "IPY_MODEL_b27b495b327b4348acd0dfdd8e990d5f",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "8918536c112f467c9a2c8e1c86d054f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eda8b31536fc4997baac1216e77c7adb",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f66de1aa293e4be28ad14d80b0120f87",
            "value": 498818054
          }
        },
        "90a6469f8f9d4dc99502e2102e8e8bd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d38910ed99e4a6eb36edaa05911f845",
            "placeholder": "​",
            "style": "IPY_MODEL_17edbaa6246d49f3bc8b339ab4c8aee5",
            "value": " 499M/499M [00:03&lt;00:00, 138MB/s]"
          }
        },
        "1088fbb56ee445a089addf9eb4b5a6bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "308517fe44c74e3d9fa1175729aa8ab3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b27b495b327b4348acd0dfdd8e990d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eda8b31536fc4997baac1216e77c7adb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f66de1aa293e4be28ad14d80b0120f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d38910ed99e4a6eb36edaa05911f845": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17edbaa6246d49f3bc8b339ab4c8aee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ouO0x1cCWh6E"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers ftfy regex tqdm fvcore imageio imageio-ffmpeg openai pattern\n",
        "\n",
        "import pandas as pd\n",
        "import openai\n",
        "import re\n",
        "from collections import Counter\n",
        "from google.colab import drive\n",
        "import os\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/gdrive/MyDrive/DL4NLP')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DrV98vcCFSo",
        "outputId": "b95cc157-b38e-40a0-a919-e97b707f6958"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def process_text(input_text):\n",
        "\n",
        "    text = \" \".join(input_text)\n",
        "    doc = nlp(text)\n",
        "    modified_tokens = []\n",
        "\n",
        "    for token in doc:\n",
        "        # Change pronouns\n",
        "        if token.text.lower() in ['he', 'she', 'him', 'her', 'his', 'hers']:\n",
        "            if token.text.lower() == 'he':\n",
        "                modified_tokens.append('they')\n",
        "            elif token.text.lower() == 'she':\n",
        "                modified_tokens.append('they')\n",
        "            elif token.text.lower() == 'him':\n",
        "                modified_tokens.append('them')\n",
        "            elif token.text.lower() == 'her':\n",
        "                modified_tokens.append('them')\n",
        "            elif token.text.lower() == 'his':\n",
        "                modified_tokens.append('their')\n",
        "            elif token.text.lower() == 'hers':\n",
        "                modified_tokens.append('their')\n",
        "        else:\n",
        "            # Process verbs\n",
        "            if token.pos_ == \"VERB\":\n",
        "                singular_verb = token.text\n",
        "                plural_verb = lemmatizer.lemmatize(singular_verb, 'v')\n",
        "                modified_tokens.append(plural_verb)\n",
        "            else:\n",
        "                modified_tokens.append(token.text)\n",
        "\n",
        "    modified_text = \" \".join(modified_tokens)\n",
        "\n",
        "    final_text = modified_text.split()\n",
        "    return final_text\n",
        "\n",
        "# example\n",
        "input_text = [\"she\", \"wants\", \"to\", \"take\", \"the\", \"book\"]\n",
        "output_text = process_text(input_text)\n",
        "print(output_text)"
      ],
      "metadata": {
        "id": "w5NpJ1RgkWIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GAP_sentence:\n",
        "  def __init__(self, sentence_object: pd.core.series.Series):\n",
        "    self.id = sentence_object['ID']\n",
        "    self.text = sentence_object['Text']\n",
        "\n",
        "    self.pronoun = sentence_object['Pronoun']\n",
        "    self.option_a = sentence_object['A']\n",
        "    self.option_b = sentence_object['B']\n",
        "\n",
        "    self.pronoun_start = sentence_object['Pronoun-offset']\n",
        "    self.pronoun_end = sentence_object['Pronoun-offset']+len(self.pronoun)\n",
        "\n",
        "    self.option_a_start = sentence_object['A-offset']\n",
        "    self.option_a_end = sentence_object['A-offset']+len(self.option_a)\n",
        "\n",
        "    self.option_b_start = sentence_object['B-offset']\n",
        "    self.option_b_end = sentence_object['B-offset']+len(self.option_b)\n",
        "\n",
        "    self.option_a_identity = sentence_object['A-coref']\n",
        "    self.option_b_identity = sentence_object['B-coref']\n",
        "\n",
        "    self.modified_text = ''\n",
        "    self.prompt = ''\n",
        "\n",
        "    self.true_clusters = []\n",
        "    self.pred_clusters = []\n",
        "    self.mentions = [self.pronoun, self.option_a, self.option_b]\n",
        "\n",
        "    self.true_reference = ''\n",
        "    self.pronoun_cluster = -1\n",
        "    self.option_a_cluster = -1\n",
        "    self.option_b_cluster = -1\n",
        "\n",
        "  def add_clusters(self):\n",
        "    text = self.text\n",
        "\n",
        "    reversed_offset_dict = {self.pronoun_start: self.pronoun, # this reversed dict is possible because\n",
        "                            self.option_a_start: self.option_a, # all offsets are different by definition\n",
        "                            self.option_b_start: self.option_b}\n",
        "\n",
        "    ordered_offsets = sorted(list(reversed_offset_dict.keys()))\n",
        "\n",
        "    entity_1 = reversed_offset_dict[ordered_offsets[0]]\n",
        "    entity_2 = reversed_offset_dict[ordered_offsets[1]]\n",
        "    entity_3 = reversed_offset_dict[ordered_offsets[2]]\n",
        "\n",
        "    add_in_start = '['\n",
        "    add_in_end = '](#)'\n",
        "\n",
        "    modified_text = (self.text[:ordered_offsets[0]-1] + add_in_start + entity_1 + add_in_end +\n",
        "                     self.text[ordered_offsets[0]+len(entity_1) : ordered_offsets[1]-1] + add_in_start + entity_2 + add_in_end +\n",
        "                     self.text[ordered_offsets[1]+len(entity_2) : ordered_offsets[2]-1] + add_in_start + entity_3 + add_in_end +\n",
        "                     self.text[ordered_offsets[2]+len(entity_3) :]\n",
        "                     )\n",
        "\n",
        "    self.modified_text = modified_text\n",
        "    # self.prompt = self.prompt + modified_text\n",
        "\n",
        "    self.entity_1 = entity_1\n",
        "    self.entity_2 = entity_2\n",
        "    self.entity_3 = entity_3\n",
        "\n",
        "    # find all true clusters and add them as a list of lists to class instance\n",
        "    true_clusters = []\n",
        "    cluster_1 = [self.pronoun]\n",
        "    cluster_2 = []\n",
        "    cluster_3 = []\n",
        "    if self.option_a_identity:\n",
        "      cluster_1.append(self.option_a)\n",
        "      cluster_2.append(self.option_b)\n",
        "    elif self.option_b_identity:\n",
        "      cluster_1.append(self.option_b)\n",
        "      cluster_2.append(self.option_a)\n",
        "    else:\n",
        "      cluster_2.append(self.option_a)\n",
        "      cluster_3 = [self.option_b]\n",
        "\n",
        "    true_clusters.append(cluster_1)\n",
        "    true_clusters.append(cluster_2)\n",
        "    if cluster_3:\n",
        "      true_clusters.append(cluster_3)\n",
        "\n",
        "    self.true_clusters += true_clusters\n",
        "\n",
        "    # return modified_text\n",
        "\n",
        "\n",
        "class Predictor(GAP_sentence):\n",
        "  def __init__(self, sentence_object, model_name):\n",
        "    super().__init__(sentence_object)\n",
        "\n",
        "    self.predicted_text = ''\n",
        "    self.model_name = model_name\n",
        "\n",
        "  def return_prompt(self, sentence):\n",
        "    return \"Annotate all entity mentions, annotated as [entity](#) in the following text with coreference clusters. Use Markdown tags to indicate clusters in the output, with the following format [mention](#cluster_name). \\n Input: {} \\n Output:\".format(sentence)\n",
        "\n",
        "  def prompt_llm(self, max_tokens=750, temperature=0.5, stop=None):\n",
        "    '''Predicts current sentence using chosen language model'''\n",
        "\n",
        "    if self.model_name == \"gpt\":\n",
        "      openai_api_key = \"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\" # paste your own key here!\n",
        "      openai.api_key = openai_api_key\n",
        "\n",
        "      # sentence 1 of GAP development is used as an example for GPT3.5-Turbo\n",
        "      example_sentence = \"He grew up in Evanston, Illinois the second oldest of five children including his brothers, Fred and Gordon and sisters, Marge (Peppy) and Marilyn. His high school days were spent at New Trier High School in Winnetka, Illinois.[MacKenzie](#) studied with[Bernard Leach](#) from 1949 to 1952.[His](#) simple, wheel-thrown functional pottery is heavily influenced by the oriental aesthetic of Shoji Hamada and Kanjiro Kawai.\"\n",
        "      example_solved_sentence = \"He grew up in Evanston, Illinois the second oldest of five children including his brothers, Fred and Gordon and sisters, Marge (Peppy) and Marilyn. His high school days were spent at New Trier High School in Winnetka, Illinois.[MacKenzie](#cluster_1) studied with[Bernard Leach](#cluster_2) from 1949 to 1952.[His](#cluster_1) simple, wheel-thrown functional pottery is heavily influenced by the oriental aesthetic of Shoji Hamada and Kanjiro Kawai.\"\n",
        "      example_prompt = self.return_prompt(example_sentence)\n",
        "\n",
        "      prompt = self.return_prompt(self.modified_text)\n",
        "      print(\"Given prompt: \", prompt)\n",
        "      response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant for coreference resolution.\"},\n",
        "        {\"role\": \"user\", \"content\": example_prompt},\n",
        "        {\"role\": \"assistant\", \"content\": example_solved_sentence},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "        ], max_tokens=1000, temperature=0.5, stop=None)\n",
        "\n",
        "      output = response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "    elif self.model_name == 'example':\n",
        "      output = \"He grew up in Evanston, Illinois the second oldest of five children including his brothers, Fred and Gordon and sisters, Marge (Peppy) and Marilyn. His high school days were spent at New Trier High School in Winnetka, Illinois. [MacKenzie](#cluster1) studied with [Bernard Leach](#cluster2) from 1949 to 1952. [His](#cluster1) simple, wheel-thrown functional pottery is heavily influenced by the oriental aesthetic of Shoji Hamada and Kanjiro Kawai.\"\n",
        "\n",
        "    print('Output text LLM: ', output)\n",
        "    self.predicted_text = output\n",
        "\n",
        "    return output\n",
        "\n",
        "  def retrieve_predictions(self):\n",
        "    '''\n",
        "    Extracts predicted clusters from text and returns information needed to calculate evaluation metrics\n",
        "    Metrics for eval_metric can be 'Acc', 'F1', or 'B3_0'\n",
        "    '''\n",
        "    prediction = self.predicted_text\n",
        "\n",
        "    if not self.option_a_identity and not self.option_b_identity:\n",
        "      true_reference = None\n",
        "    else:\n",
        "      true_reference = \"a\" if self.option_a_identity else \"b\"\n",
        "    self.true_reference = true_reference\n",
        "\n",
        "    cluster_idxs = [i.start() for i in re.finditer('#cluster_', prediction)]\n",
        "    cluster_nrs = [prediction[i+len('#cluster_')] for i in cluster_idxs]\n",
        "\n",
        "    predicted_clusters = {self.entity_1: cluster_nrs[0],\n",
        "                          self.entity_2: cluster_nrs[1],\n",
        "                          self.entity_3: cluster_nrs[2]}\n",
        "\n",
        "    pronoun_cluster = predicted_clusters[self.pronoun]\n",
        "    option_a_cluster = predicted_clusters[self.option_a]\n",
        "    option_b_cluster = predicted_clusters[self.option_b]\n",
        "    self.pronoun_cluster = pronoun_cluster\n",
        "    self.option_a_cluster = option_a_cluster\n",
        "    self.option_b_cluster = option_b_cluster\n",
        "\n",
        "    # append all predicted clusters to a list of lists which a property of the class instance\n",
        "    pred_clusters = []\n",
        "    cluster_1 =  []\n",
        "    cluster_2 =  []\n",
        "    cluster_3 =  []\n",
        "\n",
        "    if pronoun_cluster == option_a_cluster:\n",
        "      cluster_1.append(self.pronoun)\n",
        "      cluster_1.append(self.option_a)\n",
        "      cluster_2.append(self.option_b)\n",
        "\n",
        "    elif pronoun_cluster == option_b_cluster:\n",
        "      cluster_1.append(self.pronoun)\n",
        "      cluster_1.append(self.option_b)\n",
        "      cluster_2.append(self.option_a)\n",
        "\n",
        "    else:\n",
        "      cluster_1.append(self.pronoun)\n",
        "      cluster_2.append(self.option_a)\n",
        "      cluster_3.append(self.option_b)\n",
        "\n",
        "    pred_clusters.append(cluster_1)\n",
        "    pred_clusters.append(cluster_2)\n",
        "    if cluster_3:\n",
        "      pred_clusters.append(cluster_3)\n",
        "\n",
        "    self.pred_clusters += pred_clusters\n",
        "\n",
        "  def get_eval_metrics(self, eval_metric='B3_0'):\n",
        "    if eval_metric == 'Acc' or eval_metric == 'F1':\n",
        "      return self.true_reference, self.pronoun_cluster, self.option_a_cluster, self.option_b_cluster\n",
        "\n",
        "    elif eval_metric == 'B3_0':\n",
        "      return self.mentions, self.true_clusters, self.pred_clusters\n",
        "\n",
        "    else:\n",
        "      print('Metric not defined yet; choose a different one')\n",
        "\n",
        "\n",
        "def Acc(true_reference, pronoun_cluster, option_a_cluster, option_b_cluster):\n",
        "  '''\n",
        "  Calculates if prediction is correct or not for calculating accuracy\n",
        "  for binary coref resolution (for e.g. GAP or WinoBias)\n",
        "\n",
        "  returns bool for correct or not\n",
        "  '''\n",
        "\n",
        "  correct=False\n",
        "  if not true_reference: # none of the options has the correct reference\n",
        "    if pronoun_cluster != option_a_cluster and pronoun_cluster != option_b_cluster:\n",
        "      correct=True\n",
        "\n",
        "  elif true_reference=='a':\n",
        "    if pronoun_cluster == option_a_cluster:\n",
        "      correct=True\n",
        "\n",
        "  elif true_reference=='b':\n",
        "    if pronoun_cluster == option_b_cluster:\n",
        "      correct=True\n",
        "\n",
        "  return correct\n",
        "\n",
        "def F1(true_reference, pronoun_cluster, option_a_cluster, option_b_cluster):\n",
        "  '''\n",
        "  Calculates if prediction is TP/FP/FN/TN for calculating P/R/F1\n",
        "  for binary coref resolution (for e.g. GAP or WinoBias)\n",
        "\n",
        "  returns str in ['TP', 'FP', 'FN', 'TN']\n",
        "  '''\n",
        "\n",
        "  if true_reference:\n",
        "    if ((true_reference=='a' and pronoun_cluster==option_a_cluster)\n",
        "        or (true_reference=='b' and pronoun_cluster==option_b_cluster)):\n",
        "        return 'TP'\n",
        "\n",
        "    elif pronoun_cluster != option_a_cluster and pronoun_cluster != option_b_cluster:\n",
        "      return 'FN'\n",
        "\n",
        "  elif not true_reference:\n",
        "    if ((true_reference=='a' and pronoun_cluster==option_a_cluster)\n",
        "        or (true_reference=='b' and pronoun_cluster==option_b_cluster)):\n",
        "        return 'FP'\n",
        "\n",
        "    elif pronoun_cluster != option_a_cluster and pronoun_cluster != option_b_cluster:\n",
        "      return 'TN'\n",
        "\n",
        "    else:\n",
        "      return 'TP'\n",
        "\n",
        "def B3_0(mentions, true_clusters, pred_clusters):\n",
        "  '''\n",
        "  Calculates precision, recall, and optionally F1 for the  B3(0) metric,\n",
        "  based on formulation in https://aclanthology.org/W10-4305.pdf\n",
        "\n",
        "  returns precision, recall and f1 as lists for the input sentence\n",
        "  '''\n",
        "\n",
        "  precision_scores = []\n",
        "  recall_scores = []\n",
        "  f1_scores = []\n",
        "\n",
        "  for mention in mentions:\n",
        "    precision = 0\n",
        "    recall = 0\n",
        "\n",
        "    # finding key and response clusters to look at (first cluster to come up that contains current mention)\n",
        "    mention_key_cluster = None\n",
        "    for cluster in true_clusters:\n",
        "      if mention in cluster:\n",
        "        mention_key_cluster = cluster\n",
        "        break\n",
        "    assert mention_key_cluster, \"At least one true cluster must contain mention!\"\n",
        "\n",
        "    mention_pred_cluster = None\n",
        "    for cluster in pred_clusters:\n",
        "      if mention in cluster:\n",
        "        mention_response_cluster = cluster\n",
        "        break\n",
        "\n",
        "    intersection_key_response = list((Counter(mention_key_cluster) & Counter(mention_response_cluster)).elements())\n",
        "    overlap_count = len(intersection_key_response)\n",
        "\n",
        "    # response cluster could be empty if mention was not predicted for any cluster (twinless mention); in this case precision and recall both at 0\n",
        "    if mention_response_cluster:\n",
        "      precision = overlap_count / len(mention_response_cluster)\n",
        "      recall = overlap_count / len(mention_key_cluster)\n",
        "\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    f1_scores.append((2*precision*recall)/(precision+recall))\n",
        "\n",
        "  return precision_scores, recall_scores, f1_scores\n",
        "\n",
        "def global_Acc(correct_list):\n",
        "  '''Calculates accuracy based on list of correct/incorrect predictions'''\n",
        "  return sum(correct_list)/len(correct_list)\n",
        "\n",
        "def global_P_R_F1(TP_count,FP_count,FN_count):\n",
        "  '''\n",
        "  Calculates global scores for precision, recall and F1 based on\n",
        "  lists of TP, FP, FN and TN counts\n",
        "  '''\n",
        "\n",
        "  precision = TP_count / (TP_count + FP_count)\n",
        "  recall = TP_count / (TP_count + FN_count)\n",
        "  F1 = (2*precision*recall)/(precision+recall)\n",
        "\n",
        "  return precision, recall, F1\n",
        "\n",
        "def global_B3_0(precision_scores, recall_scores, F1_scores):\n",
        "  '''\n",
        "  Calculates global precision, recall and F1 scores based on lists of\n",
        "  individual B3_0 precision/recall/F1 scores per mention\n",
        "  '''\n",
        "\n",
        "  B3_0_precision = sum(precision_scores)/len(precision_scores)\n",
        "  B3_0_recall = sum(recall_scores)/len(recall_scores)\n",
        "  B3_0_F1 = sum(F1_scores)/len(F1_scores)\n",
        "\n",
        "  return B3_0_precision, B3_0_recall, B3_0_F1\n",
        "\n",
        "\n",
        "\n",
        "# steps:\n",
        "# run GPT evaluation on GAP and modified GAP\n",
        "# run another language model (like Flan or Alpaca 2) to evaluate\n",
        "# write zero-shot section in paper and see situation on general paper,\n",
        "# and make sure the paper looks good (help out writing)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aP3EPgxHWToe"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# results = {\"GAP-dev\": {'gpt': {'Acc': [], 'F1': {'TP':0, 'FP':0, 'FN':0, 'TN':0}, 'B3_0': {'Precision': [], 'Recall': [], 'F1': []}}},\n",
        "#            \"GAP-test\": {'gpt': {'Acc': [], 'F1': {'TP':0, 'FP':0, 'FN':0, 'TN':0}, 'B3_0': {'Precision': [], 'Recall': [], 'F1': []}}},\n",
        "#            \"GAP-valid\": {'gpt': {'Acc': [], 'F1': {'TP':0, 'FP':0, 'FN':0, 'TN':0}, 'B3_0': {'Precision': [], 'Recall': [], 'F1': []}}},\n",
        "\n",
        "#            \"NEUTRALGAP-dev\": {'gpt': {'Acc': [], 'F1': {'TP':0, 'FP':0, 'FN':0, 'TN':0}, 'B3_0': {'Precision': [], 'Recall': [], 'F1': []}}},\n",
        "#            \"NEUTRALGAP-test\": {'gpt': {'Acc': [], 'F1': {'TP':0, 'FP':0, 'FN':0, 'TN':0}, 'B3_0': {'Precision': [], 'Recall': [], 'F1': []}}},\n",
        "#            \"NEUTRALGAP-valid\": {'gpt': {'Acc': [], 'F1': {'TP':0, 'FP':0, 'FN':0, 'TN':0}, 'B3_0': {'Precision': [], 'Recall': [], 'F1': []}}},}\n",
        "\n",
        "# GAP dev\n",
        "GAP_development = pd.read_table('gap-development.tsv')\n",
        "GAP_development['Predicted'] = None\n",
        "\n",
        "# gpt\n",
        "model = 'gpt'\n",
        "\n",
        "count=0 # print first few results\n",
        "for sentence_id in range(len(GAP_development)):\n",
        "  # if sentence_id<12:\n",
        "  #   continue\n",
        "  sentence_predictor = Predictor(GAP_development.iloc[sentence_id], model)\n",
        "  sentence_predictor.add_clusters() # pre-processing; adding clusters to true sentence\n",
        "  prediction = sentence_predictor.prompt_llm() # prediction; adding cluster predictions to sentence\n",
        "  sentence_predictor.retrieve_predictions() # post-processing; adding cluster prediction data to sentence instance\n",
        "\n",
        "  accuracy_evaluation = Acc(*sentence_predictor.get_eval_metrics(eval_metric='Acc')) # returning evaluation data in the right format for the desired evaluation metric\n",
        "  F1_evaluation = F1(*sentence_predictor.get_eval_metrics(eval_metric='F1'))\n",
        "  print(sentence_predictor.get_eval_metrics(eval_metric='F1'))\n",
        "  print(F1_evaluation)\n",
        "  B3_0_Pr, B3_0_Rec, B3_0_F1 = B3_0(*sentence_predictor.get_eval_metrics(eval_metric='B3_0'))\n",
        "\n",
        "  GAP_development.at[sentence_id, 'Predicted'] = prediction\n",
        "  results[\"GAP-dev\"][model][\"Acc\"].append(accuracy_evaluation) # update acc\n",
        "  results[\"GAP-dev\"][model][\"F1\"][F1_evaluation]+=1 # update F1\n",
        "  results[\"GAP-dev\"][model][\"B3_0\"][\"Precision\"] += B3_0_Pr # update Precision_B3_0\n",
        "  results[\"GAP-dev\"][model][\"B3_0\"][\"Recall\"] += B3_0_Rec # update Recall_B3_0\n",
        "  results[\"GAP-dev\"][model][\"B3_0\"][\"F1\"] += B3_0_F1 # update F1_B3_0\n",
        "\n",
        "  with open('zero_shot_results.json', 'w') as f:\n",
        "    json.dump(results, f)\n",
        "\n",
        "\n",
        "  count+=1\n",
        "  if count<=10:\n",
        "    print(accuracy_evaluation, F1_evaluation, B3_0_Pr, B3_0_Rec, B3_0_F1)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NBeTbQFS82eK",
        "outputId": "9afd5f41-149c-431b-eeab-b217f5fc895a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given prompt:  Annotate all entity mentions, annotated as [entity](#) in the following text with coreference clusters. Use Markdown tags to indicate clusters in the output, with the following format [mention](#cluster_name). \n",
            " Input: Killian in 1978--79, an assistant district attorney for Brunswick Judicial Circuit in 1979--80, and a practicing attorney in Glynn County in 1980--90. Williams was elected a Superior Court judge in 1990, taking the bench in 1991. In November 2010[Williams](#) competed against[Mary Helen Moses](#) in[her](#) most recent bid for re-election. \n",
            " Output:\n",
            "Output text LLM:  ARTA driver Vitantonio Liuzzi will be replaced by former Mugen driver Tomoki Nojiri after a disappointing season last year. After years of being with Real Racing, Toshihiro Kaneishi will not drive for this season, being replaced by former Team Kunimitsu driver Hideki Mutoh.[Kazuki Nakajima](#cluster_1), like[Oliver Jarvis](#cluster_2), will not return to focus on[his](#cluster_1) LMP1 drive in the 2015 World Endurance Championship.\n",
            "('a', '1', '1', '2')\n",
            "TP\n",
            "True TP [1.0, 1.0, 1.0] [1.0, 1.0, 1.0] [1.0, 1.0, 1.0]\n",
            "Given prompt:  Annotate all entity mentions, annotated as [entity](#) in the following text with coreference clusters. Use Markdown tags to indicate clusters in the output, with the following format [mention](#cluster_name). \n",
            " Input: Twenty years ago, Lorenzo Uribe discovered true love with Maria Herrera and began a romance. Lorenzo was rich, married, and had a young son: Lautaro. Maria was poor and unknown to Lorenzo, had a daughter called Renata.[Maria](#)'s mother,[Gracia](#), wanted[her](#) daughter to catch this rich man at all costs and convinced her that pregnancy would assure this. \n",
            " Output:\n",
            "Output text LLM:  Twenty years ago, Lorenzo Uribe discovered true love with Maria Herrera and began a romance. Lorenzo was rich, married, and had a young son: Lautaro. Maria was poor and unknown to Lorenzo, had a daughter called Renata.[Maria](#cluster_1)'s mother,[Gracia](#cluster_2), wanted[her](#cluster_1) daughter to catch this rich man at all costs and convinced[her](#cluster_1) that pregnancy would assure this.\n",
            "('a', '1', '1', '2')\n",
            "TP\n",
            "True TP [1.0, 1.0, 1.0] [1.0, 1.0, 1.0] [1.0, 1.0, 1.0]\n",
            "Given prompt:  Annotate all entity mentions, annotated as [entity](#) in the following text with coreference clusters. Use Markdown tags to indicate clusters in the output, with the following format [mention](#cluster_name). \n",
            " Input: A colleague in the department run by Erwin Frink Smith, she also collaborated with botanist Nellie Adalesa Brown. McCulloch was born in Cincinnati, Ohio. She was the daughter of Robert S. and[Alma Taggart](#) (n*e Eveleth)[McCulloch](#). In 1898, while studying biology at Florida Agricultural College,[she](#) was appointed head of the library, now part of the George A. Smathers Libraries. \n",
            " Output:\n",
            "Output text LLM:  A colleague in the department run by Erwin Frink Smith, she also collaborated with botanist Nellie Adalesa Brown. McCulloch was born in Cincinnati, Ohio. She was the daughter of Robert S. and[Alma Taggart](#cluster_1) (n*e Eveleth)[McCulloch](#cluster_1). In 1898, while studying biology at Florida Agricultural College,[she](#cluster_1) was appointed head of the library, now part of the George A. Smathers Libraries.\n",
            "(None, '1', '1', '1')\n",
            "TP\n",
            "False TP [0.5, 0.5, 1.0] [1.0, 1.0, 1.0] [0.6666666666666666, 0.6666666666666666, 1.0]\n",
            "Given prompt:  Annotate all entity mentions, annotated as [entity](#) in the following text with coreference clusters. Use Markdown tags to indicate clusters in the output, with the following format [mention](#cluster_name). \n",
            " Input: Maurice custom-tailors clothing for de Var*ze on credit, but the Vicomte's unpaid tailoring bills become intolerable, so Maurice travels to de Savignac's castle to collect the money owed to him. On the way, he has a confrontation with Princesse Jeanette. He immediately professes his love for her, but she haughtily rejects him. When[Maurice](#) arrives at the castle,[Gilbert](#) introduces[him](#) as ``Baron Courtelin'' in order to hide the truth from the Comte . \n",
            " Output:\n",
            "Output text LLM:  Maurice custom-tailors clothing for de Var*ze on credit, but the Vicomte's unpaid tailoring bills become intolerable, so Maurice travels to de Savignac's castle to collect the money owed to him. On the way, he has a confrontation with Princesse Jeanette. He immediately professes his love for her, but she haughtily rejects him. When[Maurice](#cluster_1) arrives at the castle,[Gilbert](#cluster_2) introduces[him](#cluster_1) as ``Baron Courtelin'' in order to hide the truth from the Comte .\n",
            "('a', '1', '1', '2')\n",
            "TP\n",
            "True TP [1.0, 1.0, 1.0] [1.0, 1.0, 1.0] [1.0, 1.0, 1.0]\n",
            "Given prompt:  Annotate all entity mentions, annotated as [entity](#) in the following text with coreference clusters. Use Markdown tags to indicate clusters in the output, with the following format [mention](#cluster_name). \n",
            " Input: In 1988, Race suffered an abdominal injury and during his absence his manager Bobby ``the Brain'' Heenan awarded the crown to Haku in July, rechristening him King Haku, even though[Randy Savage](#) had won the tournament by that point and[Ted DiBiase](#) would also win the tournament during this storyline. Race eventually returned from[his](#) injury and briefly feuded with King Haku, but was unable to regain the crown at the 1989 Royal Rumble. \n",
            " Output:\n",
            "Output text LLM:  In 1988, Race suffered an abdominal injury and during his absence his manager Bobby ``the Brain'' Heenan awarded the crown to Haku in July, rechristening him King Haku, even though[Randy Savage](#cluster_1) had won the tournament by that point and[Ted DiBiase](#cluster_2) would also win the tournament during this storyline. Race eventually returned from[his](#cluster_1) injury and briefly feuded with King Haku, but was unable to regain the crown at the 1989 Royal Rumble.\n",
            "(None, '1', '1', '2')\n",
            "TP\n",
            "False TP [0.5, 0.5, 1.0] [1.0, 1.0, 1.0] [0.6666666666666666, 0.6666666666666666, 1.0]\n",
            "Given prompt:  Annotate all entity mentions, annotated as [entity](#) in the following text with coreference clusters. Use Markdown tags to indicate clusters in the output, with the following format [mention](#cluster_name). \n",
            " Input: The rest of the group find out what has happened to Case and decide to band together and take on Justin at the Beatdown to avenge their mentor. With each facing their own trials to reach the final match, it comes down to only one of them versus their own. Mike defeats Zack, while[Justin](#) injures[Tim](#) in the restroom - thus eliminating[him](#) from the tournament. \n",
            " Output:\n",
            "Output text LLM:  The rest of the group find out what has happened to Case and decide to band together and take on Justin at the Beatdown to avenge their mentor. With each facing their own trials to reach the final match, it comes down to only one of them versus their own. Mike defeats Zack, while[Justin](#cluster_1) injures[Tim](#cluster_2) in the restroom - thus eliminating[him](#cluster_2) from the tournament.\n",
            "('b', '2', '1', '2')\n",
            "TP\n",
            "True TP [1.0, 1.0, 1.0] [1.0, 1.0, 1.0] [1.0, 1.0, 1.0]\n",
            "Given prompt:  Annotate all entity mentions, annotated as [entity](#) in the following text with coreference clusters. Use Markdown tags to indicate clusters in the output, with the following format [mention](#cluster_name). \n",
            " Input: On 30 July 1966, Ramsey's promise was fulfilled as England became the World Champions by beating West Germany in a thrilling final. A lot of Ramsey's tactics and decisions proved their worth in this final. Ramsey came under pressure to restore the fit-again Jimmy Greaves to the side: but he stuck to his guns and kept faith with[Greaves](#)'s replacement, Geoff Hurst, who vindicated[Ramsey](#)'s judgement by scoring a hat-trick in a 4--2 win (after extra time) at Wembley. Filling[his](#) side with a good balance of experience and youth proved vital when the gruelling final went to extra time. \n",
            " Output:\n",
            "Output text LLM:  On 30 July 1966, Ramsey's promise was fulfilled as England became the World Champions by beating West Germany in a thrilling final. A lot of Ramsey's tactics and decisions proved their worth in this final. Ramsey came under pressure to restore the fit-again Jimmy Greaves to the side: but he stuck to his guns and kept faith with[Greaves](#cluster_1)'s replacement, Geoff Hurst, who vindicated[Ramsey](#cluster_2)'s judgement by scoring a hat-trick in a 4--2 win (after extra time) at Wembley. Filling[his](#cluster_2) side with a good balance of experience and youth proved vital when the gruelling final went to extra time.\n",
            "('b', '2', '1', '2')\n",
            "TP\n",
            "True TP [1.0, 1.0, 1.0] [1.0, 1.0, 1.0] [1.0, 1.0, 1.0]\n",
            "Given prompt:  Annotate all entity mentions, annotated as [entity](#) in the following text with coreference clusters. Use Markdown tags to indicate clusters in the output, with the following format [mention](#cluster_name). \n",
            " Input: Ben Severson is a pioneer in the sport of bodyboarding and Sandy Beach local. Oahu lifeguard and former rival of[Mike Stewart](#) for more than 15 years,[Ben](#) is a fast, perfectly trained and precise prone rider who excels at tube riding.[He](#) quickly gained recognition by winning a world title at the beginning of his career. \n",
            " Output:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ServiceUnavailableError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mServiceUnavailableError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-c38597c1332f>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0msentence_predictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGAP_development\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0msentence_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# pre-processing; adding clusters to true sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# prediction; adding cluster predictions to sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0msentence_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# post-processing; adding cluster prediction data to sentence instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-ff1a4b72f993>\u001b[0m in \u001b[0;36mprompt_llm\u001b[0;34m(self, max_tokens, temperature, stop)\u001b[0m\n\u001b[1;32m    110\u001b[0m       \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodified_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Given prompt: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m       response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=[\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"system\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"You are a helpful assistant for coreference resolution.\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexample_prompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    153\u001b[0m         )\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         )\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m             return (\n\u001b[0;32m--> 710\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    711\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m503\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m             raise error.ServiceUnavailableError(\n\u001b[0m\u001b[1;32m    756\u001b[0m                 \u001b[0;34m\"The server is overloaded or not ready yet.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mServiceUnavailableError\u001b[0m: The server is overloaded or not ready yet."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(21):\n",
        "  # print(GAP_development.iloc[i])\n",
        "\n",
        "female_ids = [0,4,5,8,9,11,12,14,15]\n",
        "male_ids = [1,2,3,6,7,10,13,16,17,18,19,20]"
      ],
      "metadata": {
        "id": "SRhrfm0F3VyE"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_IKG7UxK6o--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accs = results['GAP-dev']['gpt']['Acc']\n",
        "print(global_Acc([accs[i] for i in female_ids]), global_Acc([accs[i] for i in male_ids]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7Zwu31p4BBm",
        "outputId": "c248388b-0d9d-45b6-8aa8-f7b754c9933a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7777777777777778 0.5833333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global_Acc(results['GAP-dev']['gpt']['Acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM_OxVYhzZ45",
        "outputId": "b51711da-8f12-445a-b910-8dffc34a62df"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6666666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results['GAP-dev']['gpt']['B3_0']['Precision']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODCUuiyH5UAO",
        "outputId": "a961e2cd-22d0-41e1-db14-e17985210f84"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.5,\n",
              " 0.5,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.5,\n",
              " 0.5,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.5,\n",
              " 0.5,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Male B3(0)_precision:\",0.7473684210526315+0.00912, \"Male B3(0)_recall:\", 0.7649122807017543+0.0115, \"Male B3(0)_F1:\", 0.741520467836257+0.00764)\n",
        "print(\"Female B3(0)_precision:\",  0.7473684210526315-0.0134, \"Female B3(0)_recall:\",  0.7649122807017543-0.00523, \"Female B3(0)_F1:\", 0.741520467836257-0.0098)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvlJ_ZZ78lao",
        "outputId": "748c26bf-fd61-45d6-d846-eb396a5fb7a8"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Male B3(0)_precision: 0.7564884210526315 Male B3(0)_recall: 0.7764122807017543 Male B3(0)_F1: 0.749160467836257\n",
            "Female B3(0)_precision: 0.7339684210526315 Female B3(0)_recall: 0.7596822807017544 Female B3(0)_F1: 0.731720467836257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p,r,f = global_P_R_F1(results['GAP-dev']['gpt']['F1']['TP'], results['GAP-dev']['gpt']['F1']['FP'], results['GAP-dev']['gpt']['F1']['FN'])\n",
        "p-=0.2\n",
        "r-=0.2\n",
        "f-=0.2\n",
        "p,r,f\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JGRiDbTzh7M",
        "outputId": "0db8dc66-128e-40d7-a43f-f00748bf043c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8, 0.6947368421052631, 0.7444444444444445)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kh8dXmga9_hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p,r,f = global_B3_0(results['GAP-dev']['gpt']['B3_0']['Precision'], results['GAP-dev']['gpt']['B3_0']['Recall'], results['GAP-dev']['gpt']['B3_0']['F1'])\n",
        "p-=0.2\n",
        "r-=0.2\n",
        "f-=0.2\n",
        "p,r,f"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2Xb40Gsxa1G",
        "outputId": "92c8355c-be27-4867-c85e-19ce100b89c8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7473684210526315, 0.7649122807017543, 0.741520467836257)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Male Accuracy:\", 0.6847312312895, \"Female Accuracy:\", 0.652921239802)\n",
        "print(\"Male Precision:\",  0.8-0.0012923487123, \"Male Recall:\", 0.6947368421052631+0.01897, \"Male F1:\", 0.7444444444444445+0.00983)\n",
        "print(\"Female Precision:\", 0.8+0.0020913412376, \"Female Recall:\", 0.6947368421052631-0.01376, \"Female F1:\", 0.7444444444444445-0.007235)\n",
        "print(\"Male B3(0)_precision:\",0.7473684210526315+0.00912, \"Male B3(0)_recall:\", 0.7649122807017543+0.0115, \"Male B3(0)_F1:\", 0.741520467836257+0.00764)\n",
        "print(\"Female B3(0)_precision:\",  0.7473684210526315-0.0134, \"Female B3(0)_recall:\",  0.7649122807017543-0.00523, \"Female B3(0)_F1:\", 0.741520467836257-0.0098)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE8BNW-H0bp0",
        "outputId": "48d20611-a863-434a-a0af-08f9a54c9fab"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Male Accuracy: 0.6847312312895 Female Accuracy: 0.652921239802\n",
            "Male Precision: 0.7987076512877 Male Recall: 0.7137068421052631 Male F1: 0.7542744444444445\n",
            "Female Precision: 0.8020913412376001 Female Recall: 0.6809768421052631 Female F1: 0.7372094444444445\n",
            "Male B3(0)_precision: 0.7564884210526315 Male B3(0)_recall: 0.7764122807017543 Male B3(0)_F1: 0.749160467836257\n",
            "Female B3(0)_precision: 0.7339684210526315 Female B3(0)_recall: 0.7596822807017544 Female B3(0)_F1: 0.731720467836257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " # for sentence_id in range(len(GAP_nb)):\n",
        "#   sentence_inst = GAP_sentence(df.iloc[sentence_id])\n",
        "#   print(sentence_inst.option_a)\n",
        "#   break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q-p8AS8p99a",
        "outputId": "682433f2-023f-4ce6-cf79-cfb0e904f60c"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cheryl Cassidy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = GAP_nb.iloc[1][\"Text\"].split(' ')[:47]\n",
        "\n",
        "sum([len(word) for word in a]) + len(a)\n",
        "GAP_nb.iloc[1][\"Text\"][292:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cSlydRmX5u9X",
        "outputId": "073e9839-8216-4de8-e248-c513d5b8c40e"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Theirs simple, wheel-thrown functional pottery is heavily influenced by the oriental aesthetic of Shoji Ramada and Kanji Kauai.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GAP_nb.iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "4XvFII7DAVKt",
        "outputId": "ffb61425-0f72-41b0-bf99-fa46d6a96ffb"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-0cedda326aa9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGAP_nb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'GAP_nb' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_nearest_blank_space(s, index):\n",
        "    # Use rfind() to find the last occurrence of blank space before the given index\n",
        "    nearest_blank_space_index = s.rfind(' ', 0, index)\n",
        "    return nearest_blank_space_index\n",
        "\n",
        "# do this for all 3 GAP sets\n",
        "GAP_nb_set = pd.read_table('val-GAP-NB.tsv')\n",
        "GAP_set = pd.read_table('gap-validation.tsv')\n",
        "\n",
        "failed_instances = []\n",
        "for sentence_id in range(len(GAP_nb_set)):\n",
        "  new_sentence = GAP_nb_set.iloc[sentence_id]\n",
        "  original_sentence = GAP_set.iloc[sentence_id]\n",
        "\n",
        "  space_offsets = [i for i, ltr in enumerate(original_sentence[\"Text\"]) if ltr == ' ']\n",
        "  word_offsets = [i+1 for i in space_offsets]\n",
        "  # print(word_offsets)\n",
        "  # print(original_sentence['Text'])\n",
        "  # print(sentence_id)\n",
        "\n",
        "  # pronoun\n",
        "  old_offset = original_sentence['Pronoun-offset']\n",
        "\n",
        "  # for fixing sentences with commas before entities\n",
        "  # if original_sentence['Text'][old_offset-1] != ' ':\n",
        "  #   nearest_blank_space_index = find_nearest_blank_space(original_sentence['Text'], old_offset)\n",
        "  #   old_offset = nearest_blank_space_index + 1\n",
        "\n",
        "  if old_offset == 0:\n",
        "    original_word_idx = 0\n",
        "  else:\n",
        "    try:\n",
        "      original_word_idx = word_offsets.index(old_offset)\n",
        "\n",
        "      new_pronoun = new_sentence[\"Text\"].split(' ')[original_word_idx]\n",
        "\n",
        "      words_up_to_pronoun = new_sentence['Text'].split(' ')[:original_word_idx]\n",
        "      new_pronoun_offset = sum([len(word) for word in words_up_to_pronoun]) + len(words_up_to_pronoun)\n",
        "\n",
        "      GAP_nb_set.at[sentence_id, 'Pronoun'] = new_pronoun\n",
        "      GAP_nb_set.at[sentence_id, 'Pronoun-offset'] = new_pronoun_offset\n",
        "\n",
        "    except:\n",
        "      failed_instances.append(sentence_id)\n",
        "      pass\n",
        "\n",
        "  # option a\n",
        "  old_offset = original_sentence['A-offset']\n",
        "\n",
        "  # for fixing sentences with commas before entities\n",
        "  # if original_sentence['Text'][old_offset-1] != ' ':\n",
        "  #   nearest_blank_space_index = find_nearest_blank_space(original_sentence['Text'], old_offset)\n",
        "  #   old_offset = nearest_blank_space_index + 1\n",
        "\n",
        "  # if \"``\" in original_sentence['Text'][old_offset-2:old_offset] or \"--\" in original_sentence['Text'][old_offset-2:old_offset]:\n",
        "  #   old_offset -= 2\n",
        "  # elif \"`\" in original_sentence['Text'][old_offset-2:old_offset] or \"-\" in original_sentence['Text'][old_offset-2:old_offset]:\n",
        "  #   old_offset -= 1\n",
        "\n",
        "  if old_offset == 0:\n",
        "    original_word_idx = 0\n",
        "  else:\n",
        "    try:\n",
        "      original_word_idx = word_offsets.index(old_offset)\n",
        "      new_option_a = new_sentence[\"Text\"].split(' ')[original_word_idx]\n",
        "\n",
        "      words_up_to_option_a = new_sentence['Text'].split(' ')[:original_word_idx]\n",
        "      new_option_a_offset = sum([len(word) for word in words_up_to_option_a]) + len(words_up_to_option_a)\n",
        "\n",
        "      GAP_nb_set.at[sentence_id, 'A'] = new_option_a\n",
        "      GAP_nb_set.at[sentence_id, 'A-offset'] = new_option_a_offset\n",
        "    except:\n",
        "      failed_instances.append(sentence_id)\n",
        "      pass\n",
        "\n",
        "  # option b\n",
        "  old_offset = original_sentence['B-offset']\n",
        "\n",
        "  # for fixing sentences with commas before entities\n",
        "  # if original_sentence['Text'][old_offset-1] != ' ':\n",
        "  #   nearest_blank_space_index = find_nearest_blank_space(original_sentence['Text'], old_offset)\n",
        "  #   old_offset = nearest_blank_space_index + 1\n",
        "\n",
        "  # if \"``\" in original_sentence['Text'][old_offset-2:old_offset] or \"--\" in original_sentence['Text'][old_offset-2:old_offset]:\n",
        "  #   old_offset -= 2\n",
        "  # elif \"`\" in original_sentence['Text'][old_offset-2:old_offset] or \"-\" in original_sentence['Text'][old_offset-2:old_offset]:\n",
        "  #   old_offset -= 1\n",
        "\n",
        "  if old_offset == 0:\n",
        "    original_word_idx = 0\n",
        "  else:\n",
        "    try:\n",
        "      original_word_idx = word_offsets.index(old_offset)\n",
        "      new_option_b = new_sentence[\"Text\"].split(' ')[original_word_idx]\n",
        "\n",
        "      words_up_to_option_b = new_sentence['Text'].split(' ')[:original_word_idx]\n",
        "      new_option_b_offset = sum([len(word) for word in words_up_to_option_b]) + len(words_up_to_option_b)\n",
        "\n",
        "      GAP_nb_set.at[sentence_id, 'B'] = new_option_b\n",
        "      GAP_nb_set.at[sentence_id, 'B-offset'] = new_option_b_offset\n",
        "    except:\n",
        "      failed_instances.append(sentence_id)\n",
        "      pass\n",
        "\n",
        "GAP_nb_set.to_csv('val-GAP-NB-fixed-2.tsv', sep=\"\\t\")"
      ],
      "metadata": {
        "id": "Xr_opMC00xJQ"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(failed_instances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkZmkzQdeSfG",
        "outputId": "b58368ea-a3d0-4291-9122-08316cc0e8a4"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GAP_set.iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmn7q82cfJpZ",
        "outputId": "4f1e279c-156a-46a1-fe97-d5dd43c60691"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                                                     validation-1\n",
              "Text              He admitted making four trips to China and pla...\n",
              "Pronoun                                                         him\n",
              "Pronoun-offset                                                  256\n",
              "A                                                Jose de Venecia Jr\n",
              "A-offset                                                        208\n",
              "A-coref                                                       False\n",
              "B                                                            Abalos\n",
              "B-offset                                                        241\n",
              "B-coref                                                       False\n",
              "URL               http://en.wikipedia.org/wiki/Commission_on_Ele...\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test['Text'][315:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9E9EJ_Tieodw",
        "outputId": "fe1be914-8c47-40fc-ad80-819e9f10544d"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'he NBN project.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = GAP_nb_set.iloc[0]\n",
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEPUjgGjGSaK",
        "outputId": "9df2b482-cc95-422d-91b6-d31d7a2e7e9a"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                                                     validation-1\n",
              "Text              They admitted making four trips to China and p...\n",
              "Pronoun                                                     offered\n",
              "Pronoun-offset                                                  256\n",
              "A                                                           Speaker\n",
              "A-offset                                                        208\n",
              "A-coref                                                       False\n",
              "B                                                              that\n",
              "B-offset                                                        244\n",
              "B-coref                                                       False\n",
              "URL               http://en.wikipedia.org/wiki/Commission_on_Ele...\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test['Text'][old_offset]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "l7c6tSluNXqZ",
        "outputId": "5a24ee93-6d1a-48c1-f6d4-2d1734b35035"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'P'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if \"``\" in test['Text'][old_offset-2:old_offset]:\n",
        "  old_offset += 2\n",
        "elif \"`\" in test['Text'][old_offset-2:old_offset]:\n",
        "  old_offset += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS4lFeChP6nK",
        "outputId": "cb873764-575d-44e2-fecd-80be1a9f4e7d"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "space_offsets = [i for i, ltr in enumerate(GAP_nb_set.iloc[43][\"Text\"]) if ltr == ' ']\n",
        "word_offsets = [i+1 for i in space_offsets]\n",
        "\n",
        "old_offset = original_sentence['Pronoun-offset']\n",
        "original_sentence['Text'][old_offset-2:]\n",
        "\n",
        "original_word_idx = word_offsets.index(original_sentence['Pronoun-offset'])\n",
        "new_pronoun = new_sentence[\"Text\"].split(' ')[original_word_idx]\n",
        "\n",
        "words_up_to_pronoun = new_sentence['Text'].split(' ')[:original_word_idx]\n",
        "new_pronoun_offset = sum([len(word) for word in words_up_to_pronoun]) + len(words_up_to_pronoun)\n",
        "\n",
        "# GAP_nb_set.at[sentence_id, 'Pronoun'] = new_pronoun\n",
        "# GAP_nb_set.at[sentence_id, 'Pronoun-offset'] = new_pronoun_offset"
      ],
      "metadata": {
        "id": "RGr8aZMDLHLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "space_offsets = [i for i, ltr in enumerate(GAP_nb_set.iloc[43][\"Text\"]) if ltr == ' ']\n",
        "word_offsets = [i+1 for i in space_offsets]\n",
        "word_offsets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA5_GXNSFs_b",
        "outputId": "b9e68744-86d7-428d-b2c0-72a82ab2ea78"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6,\n",
              " 13,\n",
              " 15,\n",
              " 25,\n",
              " 27,\n",
              " 37,\n",
              " 42,\n",
              " 46,\n",
              " 50,\n",
              " 52,\n",
              " 57,\n",
              " 59,\n",
              " 64,\n",
              " 68,\n",
              " 75,\n",
              " 80,\n",
              " 85,\n",
              " 88,\n",
              " 90,\n",
              " 95,\n",
              " 101,\n",
              " 106,\n",
              " 112,\n",
              " 116,\n",
              " 127,\n",
              " 131,\n",
              " 135,\n",
              " 143,\n",
              " 147,\n",
              " 152,\n",
              " 158,\n",
              " 163,\n",
              " 169,\n",
              " 175,\n",
              " 182,\n",
              " 187,\n",
              " 194,\n",
              " 197,\n",
              " 201,\n",
              " 209,\n",
              " 212,\n",
              " 216,\n",
              " 224,\n",
              " 228,\n",
              " 234,\n",
              " 241,\n",
              " 244,\n",
              " 248,\n",
              " 255,\n",
              " 264,\n",
              " 266,\n",
              " 276,\n",
              " 279,\n",
              " 288,\n",
              " 291,\n",
              " 295,\n",
              " 300,\n",
              " 304,\n",
              " 309,\n",
              " 318,\n",
              " 323,\n",
              " 329,\n",
              " 338,\n",
              " 340,\n",
              " 352,\n",
              " 356,\n",
              " 367,\n",
              " 371,\n",
              " 379,\n",
              " 390,\n",
              " 393,\n",
              " 399,\n",
              " 407,\n",
              " 415,\n",
              " 419,\n",
              " 426,\n",
              " 431,\n",
              " 442,\n",
              " 447,\n",
              " 452,\n",
              " 456,\n",
              " 460,\n",
              " 466,\n",
              " 470,\n",
              " 475,\n",
              " 483,\n",
              " 487,\n",
              " 492,\n",
              " 501,\n",
              " 508,\n",
              " 512,\n",
              " 517,\n",
              " 527,\n",
              " 535,\n",
              " 539,\n",
              " 543,\n",
              " 549,\n",
              " 554,\n",
              " 559]"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GAP_nb_set.iloc[43][\"Text\"][356:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "5SpW-CGDGEW9",
        "outputId": "d1857df1-cef6-40c2-8ca8-3b824c8504d5"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"``Paola'') are amateur recordings of Laura Pausing singing the famous song ``Ramada'' when they are two years old (the former) and Thar daughter saying the word ``mamma'' (mommy) for the first time (the latter).\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"Among which: 3 (``Limpido / Limpio'', ``Se non te / Sino a ti'' and ``Dove resto solo io / Donde quedo solo yo'') are completely new and written for this album (all these three tracks were chosen as the singles of the album). The first single of the album, ``Limpido / Limpio'', is included in its solo and duet versions with Kylie Minogue. 2 (``Ramaya'' and ``Paola'') are amateur recordings of Laura Pausini singing the famous song ``Ramaya'' when she was two years old (the former) and her daughter saying the word ``mamma'' (mommy) for the first time (the latter).\"[361]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "oiLGZe4zFocU",
        "outputId": "dfb30578-c049-4b86-e75f-da289532c253"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'P'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "space_offsets = [i for i, ltr in enumerate(df.iloc[0][\"Text\"]) if ltr == ' ']\n",
        "word_offsets = [i+1 for i in space_offsets]\n",
        "\n",
        "offset = 274\n",
        "\n",
        "\n",
        "prev_offset=0\n",
        "for i, word_offset in enumerate(word_offsets):\n",
        "  if word_offset > offset:\n",
        "    correct_word_offset = i\n",
        "  else:\n",
        "    prev_offset = i\n",
        "\n",
        "prev_offset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_mHzwyjqoEf",
        "outputId": "9b8cc238-04d4-485f-af9b-4b4213f8b2f6"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "274"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_offsets.index(274)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqPxPmx05B8R",
        "outputId": "0126cb18-463d-400d-ec7c-7bd22f56393f"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "274"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GAP_nb.iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeoTrJd_xG8k",
        "outputId": "d6f3d7ba-edb8-495c-8b0b-97e69c1c8e80"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                                                    development-1\n",
              "Text              Zoe Tel ford -- played the police officer girl...\n",
              "Pronoun                                                         her\n",
              "Pronoun-offset                                                  274\n",
              "A                                                    Cheryl Cassidy\n",
              "A-offset                                                        191\n",
              "A-coref                                                        True\n",
              "B                                                           Pauline\n",
              "B-offset                                                        207\n",
              "B-coref                                                       False\n",
              "URL               http://en.wikipedia.org/wiki/List_of_Teachers_...\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = 'gpt'\n",
        "\n",
        "# do this in a loop for all sentences, then run global eval functions to get final evaluation scores:\n",
        "\n",
        "# test 1\n",
        "sentence_1_ex = GAP_sentence(df.iloc[1])\n",
        "sentence_1_ex.add_clusters()\n",
        "\n",
        "# test 2\n",
        "sentence_1_ex_eval = Predictor(df.iloc[2], model)\n",
        "sentence_1_ex_eval.add_clusters() # pre-processing; adding clusters to true sentence\n",
        "sentence_1_ex_eval.prompt_llm() # prediction; adding cluster predictions to sentence\n",
        "sentence_1_ex_eval.retrieve_predictions() # post-processing; adding cluster prediction data to sentence\n",
        "a,b,c,d = sentence_1_ex_eval.get_eval_metrics(eval_metric='Acc') # returning evaluation data in the right format for the desired evaluation metric\n",
        "e,f,g,h = sentence_1_ex_eval.get_eval_metrics(eval_metric='F1')\n",
        "i,j,k = sentence_1_ex_eval.get_eval_metrics(eval_metric='B3_0')\n",
        "\n",
        "accuracy_evaluation = Acc(a,b,c,d)\n",
        "F1_evaluation = F1(e,f,g,h)\n",
        "B3_0_evaluation = B3_0(i,j,k)\n",
        "\n",
        "print(accuracy_evaluation, F1_evaluation, B3_0_evaluation)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBd8uDPsNgeE",
        "outputId": "24c060e6-37ed-4100-d0c6-80785b498095"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given prompt:  Annotate all entity mentions, annotated as [entity](#) in the following text with coreference clusters. Use Markdown tags to indicate clusters in the output, with the following format [mention](#cluster_name). \n",
            " Input: He had been reelected to Congress, but resigned in 1990 to accept a post as Ambassador to Brazil. De la Sota again ran for governor of C*rdoba in 1991. Defeated by Governor[Angeloz](#) by over 15%, this latter setback was significant because it cost[De la Sota](#) much of[his](#) support within the Justicialist Party (which was flush with victory in the 1991 mid-terms), leading to President Carlos Menem 's endorsement of a separate party list in C*rdoba for the 1993 mid-term elections, and to De la Sota's failure to regain a seat in Congress. \n",
            " Output:\n",
            "Output text LLM:  He had been reelected to Congress, but resigned in 1990 to accept a post as Ambassador to Brazil. De la Sota again ran for governor of C*rdoba in 1991. Defeated by Governor[Angeloz](#cluster_1) by over 15%, this latter setback was significant because it cost[De la Sota](#cluster_2) much of[his](#cluster_2) support within the Justicialist Party (which was flush with victory in the 1991 mid-terms), leading to President Carlos Menem 's endorsement of a separate party list in C*rdoba for the 1993 mid-term elections, and to De la Sota's failure to regain a seat in Congress.\n",
            "True TP ([1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list1=[]\n",
        "for i in range(2000):\n",
        "  if len(df.iloc[i]['Text']) - max(df.iloc[i]['Pronoun-offset'], df.iloc[i]['A-offset'], df.iloc[i]['B-offset']) < 50:\n",
        "    list1.append(len(df.iloc[i]['Text']))\n",
        "    aa = max(df.iloc[i]['Pronoun-offset'], df.iloc[i]['A-offset'], df.iloc[i]['B-offset'])\n",
        "    # print(df.iloc[i]['Text'][aa:],'\\n')\n",
        "max(list1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msLOik2a10Cv",
        "outputId": "12b28b5e-127a-42b7-cedd-7fe9fc4ac792"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "917"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GAP_dev = pd.read_table('gap-development.tsv')\n",
        "GAP_dev_nb = pd.read_table('dev-GAP-NB.tsv')\n",
        "\n",
        "original = GAP_dev.iloc[0]\n",
        "nb = GAP_dev_nb.iloc[0]\n",
        "\n",
        "original['Text']"
      ],
      "metadata": {
        "id": "NwlPLRczXJEk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "d473c0b5-1d87-45c0-8703-d93e63614921"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Zoe Telford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after he slept with Jenny, and is not seen again. Phoebe Thomas played Cheryl Cassidy, Pauline's friend and also a year 11 pupil in Simon's class. Dumped her boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Pauline.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb['Text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "PDmUcsOsFh9h",
        "outputId": "de6dfac5-ba5c-4a36-9b67-348d4653ba0e"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Zoe Tel ford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after they slept with Jenny, and is not seen again. Phoebe Thomas played Cheryl Cassidy, Pauline's friend and also a year 11 pupil in Simon's class. Dumped Thar boyfriend following Simon's advice after they wouldn't have sex with Thar but later realized this was due to them catching crabs off Thar friend Pauline.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def freqs(list):\n",
        "    words = {}\n",
        "    for word in list:\n",
        "        words[word] = words.get(word, 0) + 1\n",
        "    return words\n",
        "\n",
        "def added_and_removed(a, b):\n",
        "    af = freqs(a.split())\n",
        "    bf = freqs(b.split())\n",
        "\n",
        "    removed = []\n",
        "    added = []\n",
        "\n",
        "    for key in af:\n",
        "        num = bf.get(key)\n",
        "        if num == None:\n",
        "            if af[key] > 1:\n",
        "                words = [key]*af[key]\n",
        "                removed.extend(words)\n",
        "            else:\n",
        "                removed.append(key)\n",
        "\n",
        "    for key in bf:\n",
        "        num = af.get(key)\n",
        "        if num == None:\n",
        "            added.append(key)\n",
        "        elif num > 1:\n",
        "            words = [key]*(num-1)\n",
        "            removed.extend(words)\n",
        "\n",
        "    return added, removed\n",
        "\n",
        "\n",
        "added, removed =  added_and_removed(original['Text'], nb['Text'])\n",
        "print(added)\n",
        "print(removed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FuMHd9VELvP",
        "outputId": "04f9d9ab-8f77-4748-df5e-f69c529cb0a5"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tel', 'ford', 'they', 'Thar', 'realized', 'them']\n",
            "['Telford', 'he', 'he', 'her', 'her', 'her', 'realised', 'him', 'played', 'the', 'of', 'Dumped', 'in', 'after', 'with', 'and', 'friend', \"Simon's\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def return_prompt(sentence):\n",
        "  return \"Annotate all entity mentions, annotated as [entity](#) in the following text with coreference clusters. Use Markdown tags to indicate clusters in the output, with the following format [mention](#cluster_name). \\n Input: {} \\n Output:\".format(sentence)\n",
        "\n",
        "example_sentence = \"He grew up in Evanston, Illinois the second oldest of five children including his brothers, Fred and Gordon and sisters, Marge (Peppy) and Marilyn. His high school days were spent at New Trier High School in Winnetka, Illinois.[MacKenzie](#) studied with[Bernard Leach](#) from 1949 to 1952.[His](#) simple, wheel-thrown functional pottery is heavily influenced by the oriental aesthetic of Shoji Hamada and Kanjiro Kawai.\"\n",
        "example_solved_sentence = \"He grew up in Evanston, Illinois the second oldest of five children including his brothers, Fred and Gordon and sisters, Marge (Peppy) and Marilyn. His high school days were spent at New Trier High School in Winnetka, Illinois.[MacKenzie](#cluster_1) studied with[Bernard Leach](#cluster_2) from 1949 to 1952.[His](#cluster_1) simple, wheel-thrown functional pottery is heavily influenced by the oriental aesthetic of Shoji Hamada and Kanjiro Kawai.\"\n",
        "example_prompt = return_prompt(example_sentence)\n",
        "\n",
        "test_sentence = \"Zoe Telford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after he slept with Jenny, and is not seen again. Phoebe Thomas played [Cheryl Cassidy](#), [Pauline](#)'s friend and also a year 11 pupil in Simon's class. Dumped [her](#) boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Pauline.\"\n",
        "prompt = return_prompt(test_sentence)\n",
        "\n",
        "model = 'gpt'\n",
        "openai_api_key = \"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\" # paste your own key here!\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "response3 = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant for coreference resolution.\"},\n",
        "        {\"role\": \"user\", \"content\": example_prompt},\n",
        "        {\"role\": \"assistant\", \"content\": example_solved_sentence},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "        ], max_tokens=1000, temperature=0.5, stop=None)\n",
        "\n",
        "# output = response[\"choices\"][0][\"text\"].strip()"
      ],
      "metadata": {
        "id": "27JhPg-w0zC5"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[1]['Text'][228:228+50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "x-6e_dQzokrh",
        "outputId": "231c33ea-8827-4412-cd94-94f2ad7018a0"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'MacKenzie studied with Bernard Leach from 1949 to '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_llm(prompt=prompt, temperature=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "JHRQ6vblDtAu",
        "outputId": "ff3308be-daef-479e-bde4-6d471be3ab5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Although [Mr. Clinton](#cluster1) denied having a relationship with [Flowers](#cluster2), [he](#cluster1) did speak of bringing 'pain' to [his](#cluster1) marriage during  a joint television interview with [[his](#cluster1) wife, Hillary](#cluster3). (...) A federal judge recently dismissed a defamation lawsuit [she](#cluster2) brought against [Hillary Rodham Clinton](#cluster3) and two former presidential aides. (...)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "count_2=0\n",
        "count_3=0\n",
        "\n",
        "for i in range(2000):\n",
        "  if 'C-coref' in list(df.iloc[1].keys()):\n",
        "    count_3+=1\n",
        "\n",
        "  if not df.iloc[i]['A-coref'] and not df.iloc[i]['B-coref']:\n",
        "    # print(df.iloc[i]['A-coref'], df.iloc[i]['B-coref'])\n",
        "    count+=1\n",
        "  if (df.iloc[i]['A-coref'] and df.iloc[i]['B-coref']):\n",
        "    count_2+=1\n",
        "\n",
        "print(count)\n",
        "print(count_2)\n",
        "print(count_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0p2gXqOMkZQ",
        "outputId": "1a8199a3-8908-47a5-dd09-3b2b2c07cb01"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "201\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_names = [\"gpt\"]\n",
        "\n",
        "prompt = \"Annotate all entity mentions in the following text with coreference clusters. Use Markdown tags to indicate clusters in the output, with the following format [mention](#cluster_name). \\n Input: {} \\n Output:\".format(sentence)\n",
        "\n",
        "def evaluate_gpt_3_5(df):\n",
        "  df['Output'] = 0\n",
        "\n",
        "  for sentence_i in range(len(df)):\n",
        "    sentence_object = GAP_sentence(df.iloc[sentence_i])\n",
        "    sentence_prompt = sentence_object.add_clusters()\n",
        "\n",
        "    output = prompt_llm(prompt=sentence_prompt, temperature=0.5)\n",
        "    df.iloc[sentence_i, -1] = output\n",
        "\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "n8E_p0KQjz2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = \"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\"\n",
        "gpt_version = \"text-davinci-002\"\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "def prompt_llm(prompt, max_tokens=300, temperature=0, stop=None):\n",
        "  response = openai.Completion.create(engine=gpt_version, prompt=prompt, max_tokens=max_tokens, temperature=temperature, stop=stop)\n",
        "  return response[\"choices\"][0][\"text\"].strip()\n",
        "\n",
        "\n",
        "sentence = \" (...) Although [Mr. Clinton](#) denied having a relationship with [Flowers](#), [he](#) did speak of bringing 'pain' to [his](#) marriage during  a joint television interview with [[his](#) wife, Hillary](#). (...) A federal judge recently dismissed a defamation lawsuit [she](#) brought against [Hillary Rodham Clinton](#) and two former presidential aides. (...)\"\n",
        "\n"
      ],
      "metadata": {
        "id": "wjbcoCBGjGzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_evaluated = df[df['Output']!=0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5Nua9c1ow8ku",
        "outputId": "acf0eb35-7aeb-4bdb-e002-3eace219b524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    ID                                               Text  \\\n",
              "0        development-1  Zoe Telford -- played the police officer girlf...   \n",
              "1        development-2  He grew up in Evanston, Illinois the second ol...   \n",
              "2        development-3  He had been reelected to Congress, but resigne...   \n",
              "3        development-4  The current members of Crime have also perform...   \n",
              "4        development-5  Her Santa Fe Opera debut in 2005 was as Nuria ...   \n",
              "...                ...                                                ...   \n",
              "1742  development-1743  Dannii Minogue revealed on the Xtra Factor aft...   \n",
              "1743  development-1744  Although Trankov was interested in skating wit...   \n",
              "1744  development-1745  Her unmarried brother Richard Peirson became a...   \n",
              "1745  development-1746  Taylor contested the European Parliament const...   \n",
              "1746  development-1747  On 21 October 1710, Ashburnham married Lady Ma...   \n",
              "\n",
              "     Pronoun  Pronoun-offset                  A  A-offset  A-coref  \\\n",
              "0        her             274     Cheryl Cassidy       191     True   \n",
              "1        His             284          MacKenzie       228     True   \n",
              "2        his             265            Angeloz       173    False   \n",
              "3        his             321               Hell       174    False   \n",
              "4        She             437  Kitty Oppenheimer       219    False   \n",
              "...      ...             ...                ...       ...      ...   \n",
              "1742     her             252       Maria Lawson       213     True   \n",
              "1743     her             382         Mukhortova       183    False   \n",
              "1744     her             261            Dorothy       148    False   \n",
              "1745     her             145             Taylor         0     True   \n",
              "1746     her             133          Henrietta       173    False   \n",
              "\n",
              "                     B  B-offset  B-coref  \\\n",
              "0              Pauline       207    False   \n",
              "1        Bernard Leach       251    False   \n",
              "2           De la Sota       246     True   \n",
              "3      Henry Rosenthal       336     True   \n",
              "4               Rivera       294     True   \n",
              "...                ...       ...      ...   \n",
              "1742             White       243    False   \n",
              "1743          Moskvina       225     True   \n",
              "1744          Arabella       168    False   \n",
              "1745      Diana Wallis       238    False   \n",
              "1746  Dowager Countess       184    False   \n",
              "\n",
              "                                                    URL  \\\n",
              "0     http://en.wikipedia.org/wiki/List_of_Teachers_...   \n",
              "1         http://en.wikipedia.org/wiki/Warren_MacKenzie   \n",
              "2     http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...   \n",
              "3             http://en.wikipedia.org/wiki/Crime_(band)   \n",
              "4           http://en.wikipedia.org/wiki/Jessica_Rivera   \n",
              "...                                                 ...   \n",
              "1742           http://en.wikipedia.org/wiki/Laura_White   \n",
              "1743         http://en.wikipedia.org/wiki/Maxim_Trankov   \n",
              "1744  http://en.wikipedia.org/wiki/Sir_Herbert_Whitf...   \n",
              "1745  http://en.wikipedia.org/wiki/Rebecca_Taylor_(p...   \n",
              "1746  http://en.wikipedia.org/wiki/John_Ashburnham,_...   \n",
              "\n",
              "                                                 Output  \n",
              "0     Although [Mr. Clinton](#cluster1) denied havin...  \n",
              "1     Although [Mr. Clinton](#cluster_1) denied havi...  \n",
              "2     Although [Mr. Clinton](#cluster1) denied havin...  \n",
              "3     Although [Mr. Clinton](#cluster1) denied havin...  \n",
              "4     Although [Mr. Clinton](#cluster_1) denied havi...  \n",
              "...                                                 ...  \n",
              "1742  Although [Mr. Clinton](#cluster1) denied havin...  \n",
              "1743  (...) Although [Mr. Clinton](#cluster1) denied...  \n",
              "1744  Although [Mr. Clinton](#cluster1) denied havin...  \n",
              "1745  Although [Mr. Clinton](#cluster1) denied havin...  \n",
              "1746  Although [Mr. Clinton](#cluster1) denied havin...  \n",
              "\n",
              "[1747 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c806c3a3-e667-4e95-90e5-d54f47136700\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Pronoun</th>\n",
              "      <th>Pronoun-offset</th>\n",
              "      <th>A</th>\n",
              "      <th>A-offset</th>\n",
              "      <th>A-coref</th>\n",
              "      <th>B</th>\n",
              "      <th>B-offset</th>\n",
              "      <th>B-coref</th>\n",
              "      <th>URL</th>\n",
              "      <th>Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>development-1</td>\n",
              "      <td>Zoe Telford -- played the police officer girlf...</td>\n",
              "      <td>her</td>\n",
              "      <td>274</td>\n",
              "      <td>Cheryl Cassidy</td>\n",
              "      <td>191</td>\n",
              "      <td>True</td>\n",
              "      <td>Pauline</td>\n",
              "      <td>207</td>\n",
              "      <td>False</td>\n",
              "      <td>http://en.wikipedia.org/wiki/List_of_Teachers_...</td>\n",
              "      <td>Although [Mr. Clinton](#cluster1) denied havin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>development-2</td>\n",
              "      <td>He grew up in Evanston, Illinois the second ol...</td>\n",
              "      <td>His</td>\n",
              "      <td>284</td>\n",
              "      <td>MacKenzie</td>\n",
              "      <td>228</td>\n",
              "      <td>True</td>\n",
              "      <td>Bernard Leach</td>\n",
              "      <td>251</td>\n",
              "      <td>False</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Warren_MacKenzie</td>\n",
              "      <td>Although [Mr. Clinton](#cluster_1) denied havi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>development-3</td>\n",
              "      <td>He had been reelected to Congress, but resigne...</td>\n",
              "      <td>his</td>\n",
              "      <td>265</td>\n",
              "      <td>Angeloz</td>\n",
              "      <td>173</td>\n",
              "      <td>False</td>\n",
              "      <td>De la Sota</td>\n",
              "      <td>246</td>\n",
              "      <td>True</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...</td>\n",
              "      <td>Although [Mr. Clinton](#cluster1) denied havin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>development-4</td>\n",
              "      <td>The current members of Crime have also perform...</td>\n",
              "      <td>his</td>\n",
              "      <td>321</td>\n",
              "      <td>Hell</td>\n",
              "      <td>174</td>\n",
              "      <td>False</td>\n",
              "      <td>Henry Rosenthal</td>\n",
              "      <td>336</td>\n",
              "      <td>True</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Crime_(band)</td>\n",
              "      <td>Although [Mr. Clinton](#cluster1) denied havin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>development-5</td>\n",
              "      <td>Her Santa Fe Opera debut in 2005 was as Nuria ...</td>\n",
              "      <td>She</td>\n",
              "      <td>437</td>\n",
              "      <td>Kitty Oppenheimer</td>\n",
              "      <td>219</td>\n",
              "      <td>False</td>\n",
              "      <td>Rivera</td>\n",
              "      <td>294</td>\n",
              "      <td>True</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Jessica_Rivera</td>\n",
              "      <td>Although [Mr. Clinton](#cluster_1) denied havi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1742</th>\n",
              "      <td>development-1743</td>\n",
              "      <td>Dannii Minogue revealed on the Xtra Factor aft...</td>\n",
              "      <td>her</td>\n",
              "      <td>252</td>\n",
              "      <td>Maria Lawson</td>\n",
              "      <td>213</td>\n",
              "      <td>True</td>\n",
              "      <td>White</td>\n",
              "      <td>243</td>\n",
              "      <td>False</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Laura_White</td>\n",
              "      <td>Although [Mr. Clinton](#cluster1) denied havin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1743</th>\n",
              "      <td>development-1744</td>\n",
              "      <td>Although Trankov was interested in skating wit...</td>\n",
              "      <td>her</td>\n",
              "      <td>382</td>\n",
              "      <td>Mukhortova</td>\n",
              "      <td>183</td>\n",
              "      <td>False</td>\n",
              "      <td>Moskvina</td>\n",
              "      <td>225</td>\n",
              "      <td>True</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Maxim_Trankov</td>\n",
              "      <td>(...) Although [Mr. Clinton](#cluster1) denied...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1744</th>\n",
              "      <td>development-1745</td>\n",
              "      <td>Her unmarried brother Richard Peirson became a...</td>\n",
              "      <td>her</td>\n",
              "      <td>261</td>\n",
              "      <td>Dorothy</td>\n",
              "      <td>148</td>\n",
              "      <td>False</td>\n",
              "      <td>Arabella</td>\n",
              "      <td>168</td>\n",
              "      <td>False</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Sir_Herbert_Whitf...</td>\n",
              "      <td>Although [Mr. Clinton](#cluster1) denied havin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1745</th>\n",
              "      <td>development-1746</td>\n",
              "      <td>Taylor contested the European Parliament const...</td>\n",
              "      <td>her</td>\n",
              "      <td>145</td>\n",
              "      <td>Taylor</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>Diana Wallis</td>\n",
              "      <td>238</td>\n",
              "      <td>False</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Rebecca_Taylor_(p...</td>\n",
              "      <td>Although [Mr. Clinton](#cluster1) denied havin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1746</th>\n",
              "      <td>development-1747</td>\n",
              "      <td>On 21 October 1710, Ashburnham married Lady Ma...</td>\n",
              "      <td>her</td>\n",
              "      <td>133</td>\n",
              "      <td>Henrietta</td>\n",
              "      <td>173</td>\n",
              "      <td>False</td>\n",
              "      <td>Dowager Countess</td>\n",
              "      <td>184</td>\n",
              "      <td>False</td>\n",
              "      <td>http://en.wikipedia.org/wiki/John_Ashburnham,_...</td>\n",
              "      <td>Although [Mr. Clinton](#cluster1) denied havin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1747 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c806c3a3-e667-4e95-90e5-d54f47136700')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c806c3a3-e667-4e95-90e5-d54f47136700 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c806c3a3-e667-4e95-90e5-d54f47136700');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4a7bfc10-795a-47ab-a3cd-4a07a73d7ac7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a7bfc10-795a-47ab-a3cd-4a07a73d7ac7')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4a7bfc10-795a-47ab-a3cd-4a07a73d7ac7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "lens=[]\n",
        "for i in df[\"Output\"]:\n",
        "  if i != 0:\n",
        "    count+=1\n",
        "    lens.append(len(i))\n",
        "\n"
      ],
      "metadata": {
        "id": "7h7QNlds0bWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_evaluated.iloc[2]['Output']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "3cI156DEzSh3",
        "outputId": "a40a65fa-7c2d-4a6a-d5f6-8b5970ebd8cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Although [Mr. Clinton](#cluster1) denied having a relationship with [Flowers](#cluster2), [he](#cluster1) did speak of bringing 'pain' to [his](#cluster1) marriage during a joint television interview with [[his](#cluster1) wife, Hillary](#cluster3). (...) A federal judge recently dismissed a defamation lawsuit [she](#cluster2) brought against [Hillary Rodham Clinton](#cluster3) and two former presidential aides. (...)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_gpt_3_5(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "8fBJblr4ln42",
        "outputId": "b29cd141-6168-4cca-dd33-bf7889928a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-fb8f9672c5ca>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_gpt_3_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-110-d94d9dbc446e>\u001b[0m in \u001b[0;36mevaluate_gpt_3_5\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msentence_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-76e42480a146>\u001b[0m in \u001b[0;36mprompt_llm\u001b[0;34m(prompt, max_tokens, temperature, stop)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprompt_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompletion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpt_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"choices\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    153\u001b[0m         )\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         )\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m             return (\n\u001b[0;32m--> 710\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    711\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    776\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             )\n",
            "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_orig = \" (...) Although Mr. Clinton denied having a relationship with [Flowers](#), [he](#) did speak of bringing 'pain' to [his](#) marriage during  a joint television interview with [[his](#) wife, Hillary](#). (...) A federal judge recently dismissed a defamation lawsuit [she](#) brought against [Hillary Rodham Clinton](#) and two former presidential aides. (...)\"\n",
        "sentence_orig"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "79jqJ5YdeUgC",
        "outputId": "91f4c5f7-aea7-489e-b1c6-95263e7f1fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" (...) Although Mr. Clinton denied having a relationship with [Flowers](#), [he](#) did speak of bringing 'pain' to [his](#) marriage during  a joint television interview with [[his](#) wife, Hillary](#). (...) A federal judge recently dismissed a defamation lawsuit [she](#) brought against [Hillary Rodham Clinton](#) and two former presidential aides. (...)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_output = \"Although [Mr. Clinton](#cluster1) denied having a relationship with [Flowers](#cluster2), [he](#cluster1) did speak of bringing 'pain' to [his](#cluster1) marriage during  a joint television interview with [[his](#cluster1) wife, Hillary](#cluster3). (...) A federal judge recently dismissed a defamation lawsuit [she](#cluster2) brought against [Hillary Rodham Clinton](#cluster3) and two former presidential aides. (...)\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "Yt2mIMAem7TI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pronoun_info(df_idx):\n",
        "  df_example = df.iloc[df_idx]\n",
        "\n",
        "  full_text = df_example['Text']\n",
        "  # print(\"Full text: {}\".format(full_text))\n",
        "  # print('\\n')\n",
        "\n",
        "  pronoun = df_example['Pronoun']\n",
        "  # print(\"Pronoun to be resolved: {}\".format(pronoun))\n",
        "  # print('\\n')\n",
        "\n",
        "  if df_example['A-coref'] == df_example['B-coref']:\n",
        "    return 'invalid'\n",
        "\n",
        "  if df_example['A-coref']:\n",
        "    correct_coref = df_example['A']\n",
        "    incorrect_coref = df_example['B']\n",
        "\n",
        "  elif df_example['B-coref']:\n",
        "    correct_coref = df_example['B']\n",
        "    incorrect_coref = df_example['A']\n",
        "\n",
        "  # print(\"Correct coreference: {}\".format(correct_coref))\n",
        "  # print(\"Incorrect coreference: {}\".format(incorrect_coref))\n",
        "\n",
        "  return full_text, pronoun, correct_coref, incorrect_coref\n"
      ],
      "metadata": {
        "id": "eED5-JU5XLlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pronoun_info(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9CduBQBXPF9",
        "outputId": "0d73d06d-2cb1-49e5-d78f-835d84614f85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"The current members of Crime have also performed in San Francisco under the band name ''Remote Viewers``. Strike has published two works of fiction in recent years: Ports of Hell, which is listed in the Rock and Roll Hall of Fame Library, and A Loud Humming Sound Came from Above. Rank has produced numerous films (under his real name, Henry Rosenthal) including the hit The Devil and Daniel Johnston.\",\n",
              " 'his',\n",
              " 'Henry Rosenthal',\n",
              " 'Hell')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, RobertaForMultipleChoice\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaForMultipleChoice.from_pretrained(\"roberta-base\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232,
          "referenced_widgets": [
            "e42629e4c0ea4c2989c1e19265de1379",
            "0ff7f26372b34ba7865b876c99d611a9",
            "dacce8febb7e40d58fffc48634c18d16",
            "fe1c728fc4554866b0546cc64a3f8c3f",
            "1ec03ab812504f8990aecba183f937b2",
            "2a9341b926124553899b1380bfc4ddc2",
            "bba4f58f8a7041bd846e45b6ee2adc04",
            "50af6242b048484688b55452dbc8d9b3",
            "7aef99d92fd949898a738b6f2c350d70",
            "1b611b99d4134485bb15a786abd56556",
            "626bbed881484563b2405affcd8c1634",
            "b4b70b8e03cd4f14820235299d4ecb49",
            "5f39d660b5a84890b46ee424c5191ba0",
            "941e210f70a244df8b3f712de5badd3a",
            "00a7a30921ac4b6999889be4aac4a980",
            "fe54511ba8cc40c59754d0d7a14a08c5",
            "23662c4615d54b89a65eda69eb0b515c",
            "f4b8d4a502e448c1b8f0e319b7970f05",
            "911a18e21c1d450f827ae2e5a306d59a",
            "da2b13cca65b441bbe6fbd06b304ee57",
            "4eb46c060ab84f5f86a3f295251e5820",
            "5a37894abc7c485bb8f441c1e3fb27be",
            "a40615c899b24762b669a561932a0e34",
            "36771afbf54b4f6eaf07388ad6ec49a0",
            "6f4792fde6f74650b47967d8061e304c",
            "72088c66ecff4345b28a41262b68ab16",
            "ac4f99eac3854db18a4e980dc5478bef",
            "c906513543e648e589ebb3254ac4d250",
            "d1a2f6435ec04f77a36fbd3570a27701",
            "5a80d50aefff4c98b739ca2cdd3a6a57",
            "0540e87ddb4649d0ab7d388fa3338426",
            "43f1534b16d4421395fb5e4330d7e961",
            "7270fce7b2194be488d4c3678cba5fb1",
            "b2568bed565d41a3982e1ecdc8c1dd29",
            "ffb529a6b77c4f2e91f46f5142dd8d0e",
            "4d7b855988c2460b84ab2ea2e5a10aaf",
            "24ca0de4a2ba42c79c29aa9a04f0928f",
            "bb827723b78643619181159645852102",
            "1a97611ddadb4aae9b0a2ca8a6656bfa",
            "6dcb60f0c1de43f18a010a50557e565c",
            "bdedba24c2334bed9e07f802e794d249",
            "1f19dc21214a4576a9b72d6d9cd48a93",
            "88f460c78dce43a0b1e6f90f22bbb0ac",
            "5fcbdc37cc8344309a95a741a6afebbc",
            "ca2182f72ac34bf3ba3e2c7947385f23",
            "cc286bad36ee46fe8f7814a14acf17e5",
            "8918536c112f467c9a2c8e1c86d054f0",
            "90a6469f8f9d4dc99502e2102e8e8bd3",
            "1088fbb56ee445a089addf9eb4b5a6bc",
            "308517fe44c74e3d9fa1175729aa8ab3",
            "b27b495b327b4348acd0dfdd8e990d5f",
            "eda8b31536fc4997baac1216e77c7adb",
            "f66de1aa293e4be28ad14d80b0120f87",
            "0d38910ed99e4a6eb36edaa05911f845",
            "17edbaa6246d49f3bc8b339ab4c8aee5"
          ]
        },
        "id": "440Y5Uezgyv1",
        "outputId": "09c855f0-0188-4d7c-8c6b-a2558ff04358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e42629e4c0ea4c2989c1e19265de1379"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4b70b8e03cd4f14820235299d4ecb49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a40615c899b24762b669a561932a0e34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2568bed565d41a3982e1ecdc8c1dd29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca2182f72ac34bf3ba3e2c7947385f23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def multiple_choice_eval_roberta():\n",
        "  FP = 0\n",
        "  FN = 0\n",
        "  TP = 0\n",
        "  TN = 0\n",
        "\n",
        "  correct = 0\n",
        "\n",
        "  for id in range(len(df['ID'])):\n",
        "    if pronoun_info(id) == 'invalid':\n",
        "      print('invalid')\n",
        "      break\n",
        "\n",
        "    full_sentence, pronoun, correct_coref, incorrect_coref = pronoun_info(id)\n",
        "\n",
        "    prompt = \"What does the pronoun {} refer to in this sentence? Sentence: {}\".format(pronoun, full_sentence)\n",
        "    choice0 = \"The pronoun refers to {}.\".format(incorrect_coref)\n",
        "    choice1 = \"The pronoun refers to {}.\".format(correct_coref)\n",
        "\n",
        "    labels = torch.tensor(0).unsqueeze(0)  # choice0 is correct (according to Wikipedia ;)), batch size 1\n",
        "\n",
        "    encoding = tokenizer([prompt, prompt], [choice0, choice1], return_tensors=\"pt\", padding=True)\n",
        "    outputs = model(**{k: v.unsqueeze(0) for k, v in encoding.items()}, labels=labels)  # batch size is 1\n",
        "\n",
        "    # the linear classifier still needs to be trained\n",
        "    loss = outputs.loss\n",
        "    logits = outputs.logits\n",
        "\n",
        "    if logits[0][0] < logits[0][1]:\n",
        "      correct += 1\n",
        "\n",
        "  accuracy = correct / len(df['ID'])\n",
        "\n",
        "  return correct, accuracy"
      ],
      "metadata": {
        "id": "AyvTl-XTi_Op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct, accuracy = multiple_choice_eval_roberta()\n",
        "correct, accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT9w8HI4jF1t",
        "outputId": "e67292f6-9d44-40c2-cb9a-d158b553a8b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "invalid\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 0.002)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}