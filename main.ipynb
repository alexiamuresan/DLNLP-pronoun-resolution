{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unbiased Pronoun Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/dl4nlp-pr/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.utils import *\n",
    "from src.data_utils import *\n",
    "from src.models import *\n",
    "from src.train import *\n",
    "from src.zs_utils import *\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_seed(42)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f'using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Zero-shot CR using LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify gap test set zs using gpt3\n",
    "data_path = 'data/gap/gap-test.tsv'\n",
    "num_samples = 10\n",
    "output_path = None\n",
    "\n",
    "# call gpt api\n",
    "responses = classify_coref_zs(data_path, num_samples, output_path=output_path)\n",
    "for i, response in enumerate(responses):\n",
    "    print(f'response {i}: {response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Coref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-shot eval on GAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/12/2023 14:50:44 - INFO - \t missing_keys: []\n",
      "10/12/2023 14:50:44 - INFO - \t unexpected_keys: []\n",
      "10/12/2023 14:50:44 - INFO - \t mismatched_keys: []\n",
      "10/12/2023 14:50:44 - INFO - \t error_msgs: []\n",
      "10/12/2023 14:50:44 - INFO - \t Model Parameters: 590.0M, Transformer: 434.6M, Coref head: 155.4M\n",
      "10/12/2023 14:50:44 - INFO - \t Tokenize 2000 inputs...\n",
      "Map: 100%|██████████| 2000/2000 [00:07<00:00, 270.48 examples/s]\n",
      "10/12/2023 14:50:51 - INFO - \t ***** Running Inference on 2000 texts *****\n",
      "Inference: 100%|██████████| 2000/2000 [00:42<00:00, 47.53it/s]\n",
      "10/12/2023 14:51:34 - INFO - \t Tokenize 2000 inputs...\n",
      "Map: 100%|██████████| 2000/2000 [00:06<00:00, 314.91 examples/s]\n",
      "10/12/2023 14:51:40 - INFO - \t ***** Running Inference on 2000 texts *****\n",
      "Inference: 100%|██████████| 2000/2000 [00:41<00:00, 47.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting labels for 2000 samples using LingMessCoref...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:00, 13341.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "evaluating metrics on None for lmcoref on GAP test...\n",
      "acc: 0.707\n",
      "f1: 0.674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# classify gap test set zs using fcoref\n",
    "data_path = 'data/gap/gap-test.tsv'  # path to gap test set\n",
    "num_samples = None # number of samples to classify\n",
    "model_name = 'lmcoref'  # either 'fcoref' or 'lmcoref'\n",
    "# init fcoref classifier\n",
    "fcr_classifier = FCorefClassifier(model_name, data_path, num_samples)\n",
    "# get cluster preds\n",
    "cluster_preds = fcr_classifier.pred_cr_clusters()\n",
    "# get label preds\n",
    "labels, preds = fcr_classifier.pred_cr_labels(verbose=False)\n",
    "\n",
    "# eval \n",
    "metrics = ['acc', 'f1'] # metrics to eval\n",
    "res_file_path = None # path to save results\n",
    "print(f'evaluating metrics on {num_samples} for {model_name} on GAP test...')\n",
    "eval_res = eval_preds(labels, preds, metrics)\n",
    "for metric, val in eval_res.items():\n",
    "    print(f'{metric}: {val:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify GAP dataset to gender-neutral pronouns   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neil/dl4nlp-pr/src/data_utils.py:245: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'His' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_gap_gn.loc[i, 'Pronoun_old'] = row['Pronoun']    # save the old pronoun\n",
      "5it [03:45, 45.05s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "One or more markers not found in text.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/neil/dl4nlp-pr/main.ipynb Cell 14\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bneil-vm5.us-west4-b.ellogon-366011/home/neil/dl4nlp-pr/main.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m gap_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdata/gap/gap-test.tsv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bneil-vm5.us-west4-b.ellogon-366011/home/neil/dl4nlp-pr/main.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m gap_gn_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdata/gap/gap-test-gn-v2.tsv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bneil-vm5.us-west4-b.ellogon-366011/home/neil/dl4nlp-pr/main.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m mod_texts \u001b[39m=\u001b[39m create_gn_gap(gap_path, gap_gn_path)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bneil-vm5.us-west4-b.ellogon-366011/home/neil/dl4nlp-pr/main.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# sanity check for new offsets\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bneil-vm5.us-west4-b.ellogon-366011/home/neil/dl4nlp-pr/main.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# check_offsets(gap_gn_path, num_rows=1000)\u001b[39;00m\n",
      "File \u001b[0;32m~/dl4nlp-pr/src/data_utils.py:241\u001b[0m, in \u001b[0;36mcreate_gn_gap\u001b[0;34m(data_path, output_path)\u001b[0m\n\u001b[1;32m    239\u001b[0m text \u001b[39m=\u001b[39m gpt\u001b[39m.\u001b[39mcheck_grammar(text)\n\u001b[1;32m    240\u001b[0m \u001b[39m# remove markers & get new offsets\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m text, offsets \u001b[39m=\u001b[39m remove_markers(text)\n\u001b[1;32m    242\u001b[0m \u001b[39m# update the df\u001b[39;00m\n\u001b[1;32m    243\u001b[0m df_gap_gn\u001b[39m.\u001b[39mloc[i, \u001b[39m'\u001b[39m\u001b[39mText\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m text \u001b[39m# update the text\u001b[39;00m\n",
      "File \u001b[0;32m~/dl4nlp-pr/src/data_utils.py:187\u001b[0m, in \u001b[0;36mremove_markers\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39m# ensure all markers are found\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m a_marker_pos \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m b_marker_pos \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m p_marker_pos \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[0;32m--> 187\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mOne or more markers not found in text.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[39m# create a list of (marker_position, original_offset_name) tuples\u001b[39;00m\n\u001b[1;32m    190\u001b[0m marker_positions \u001b[39m=\u001b[39m [(a_marker_pos, \u001b[39m'\u001b[39m\u001b[39mA-offset\u001b[39m\u001b[39m'\u001b[39m), (b_marker_pos, \u001b[39m'\u001b[39m\u001b[39mB-offset\u001b[39m\u001b[39m'\u001b[39m), (p_marker_pos, \u001b[39m'\u001b[39m\u001b[39mPronoun-offset\u001b[39m\u001b[39m'\u001b[39m)]\n",
      "\u001b[0;31mValueError\u001b[0m: One or more markers not found in text."
     ]
    }
   ],
   "source": [
    "# create modified gap test set\n",
    "gap_path = 'data/gap/gap-test.tsv'\n",
    "gap_gn_path = 'data/gap/gap-test-gn-v2.tsv'\n",
    "mod_texts = create_gn_gap(gap_path, gap_gn_path)\n",
    "\n",
    "# sanity check for new offsets\n",
    "# check_offsets(gap_gn_path, num_rows=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4nlp-pr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
