{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unbiased Pronoun Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from src.utils import *\n",
    "from src.data_utils import *\n",
    "from src.models import *\n",
    "from src.train import *\n",
    "from src.zs_utils import *\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'using device: {device}')\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # disable HF tokenizer parallelism\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1' # for debugging cuda errors\n",
    "# os.environ['TORCH_USE_CUDA_DSA'] = 'true'\n",
    "# set torch matmul precision\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Finetune & eval LM on dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train set: 2000 | val set: 454 | test set: 2000\n"
     ]
    }
   ],
   "source": [
    "# create data module\n",
    "root_dir = 'data/gap/'  # root dir of GAP dataset\n",
    "bsz = 32    # batch size\n",
    "data_module = GAPDataModule(root_dir, bsz=bsz)\n",
    "print(f'size of train set: {len(data_module.train_dataset)} | val set: {len(data_module.val_dataset)} | test set: {len(data_module.test_dataset)}')\n",
    "\n",
    "# create data loaders\n",
    "train_loader, val_loader, test_loader = data_module.train_dataloader(), data_module.val_dataloader(), data_module.test_dataloader()\n",
    "\n",
    "# get value counts of labels\n",
    "# get_value_counts(data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train (finetune) LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type               | Params\n",
      "---------------------------------------------\n",
      "0 | model | RobertaModel       | 355 M \n",
      "1 | fc    | Linear             | 3.1 K \n",
      "2 | loss  | CrossEntropyLoss   | 0     \n",
      "3 | acc   | MulticlassAccuracy | 0     \n",
      "4 | f1    | MulticlassF1Score  | 0     \n",
      "---------------------------------------------\n",
      "355 M     Trainable params\n",
      "0         Non-trainable params\n",
      "355 M     Total params\n",
      "1,421.451 Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 63/63 [00:23<00:00,  2.73it/s, v_num=last]       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1.155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 63/63 [00:22<00:00,  2.74it/s, v_num=last]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.108 >= min_delta = 0.0. New best score: 1.047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 63/63 [00:22<00:00,  2.74it/s, v_num=last]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.037 >= min_delta = 0.0. New best score: 1.010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 63/63 [00:22<00:00,  2.75it/s, v_num=last]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 3 records. Best score: 1.010. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 63/63 [00:22<00:00,  2.75it/s, v_num=last]\n"
     ]
    }
   ],
   "source": [
    "# %%script false --no-raise-error\n",
    "# clear GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# create the model\n",
    "lm_name = 'nielsr/coref-roberta-large'\n",
    "model = GAPCorefClassifier(lm_name)\n",
    "\n",
    "# training args\n",
    "args = {'lm_name': lm_name, 'num_epochs': 10, 'precision': '16-mixed', 'patience': 3, 'ckpt_name': 'ckpt_best', 'resume_ckpt': None, 'grad_batches': 4, 'save_top_k': 1}\n",
    "\n",
    "# train\n",
    "model, trainer = train(model, train_loader, val_loader, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/dl4nlp-pr/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:149: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "  rank_zero_warn(\n",
      "Restoring states from the checkpoint path at /home/neil/dl4nlp-pr/model_ckpts/GAPCorefClassifier/nielsr/coref-roberta-large/ckpt_best.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/neil/dl4nlp-pr/model_ckpts/GAPCorefClassifier/nielsr/coref-roberta-large/ckpt_best.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 63/63 [00:06<00:00,  9.17it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Runningstage.testing metric      DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.3346666991710663\n",
      "         test_f1            0.19895586371421814\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.3346666991710663, 'test_f1': 0.19895586371421814}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "trainer.test(dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test predictions\n",
    "test_out = trainer.predict(dataloaders=test_loader)\n",
    "# stack batch preds and labels\n",
    "test_labels = torch.cat([x[0] for x in test_out]).cpu().numpy() \n",
    "test_preds = torch.cat([x[1] for x in test_out])\n",
    "# get value counts of 0's & 1's in test_labels, test_preds\n",
    "unique_labels, counts_labels = np.unique(test_labels, return_counts=True)\n",
    "unique_preds, counts_preds = np.unique(test_preds, return_counts=True)\n",
    "\n",
    "# print the counts\n",
    "print(f\"counts in test_labels: {dict(zip(unique_labels, counts_labels))}\")\n",
    "print(f\"counts in test_preds: {dict(zip(unique_preds, counts_preds))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Zero-shot CR using LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response 0: Dehner\n",
      "response 1: Dehner\n",
      "response 2: Dehner\n",
      "response 3: Alonso\n",
      "response 4: Alonso\n",
      "response 5: Alonso\n",
      "response 6: Ali Aladhadh\n",
      "response 7: Ali Aladhadh\n",
      "response 8: Ali Aladhadh\n",
      "response 9: Pisciotta\n",
      "response 10: Pisciotta\n",
      "response 11: Pisciotta\n",
      "response 12: Eddie\n",
      "response 13: Eddie\n",
      "response 14: Eddie\n",
      "response 15: Jewel Staite\n",
      "response 16: Jewel Staite\n",
      "response 17: Jewel Staite\n",
      "response 18: Allison\n",
      "response 19: Allison\n",
      "response 20: Allison\n",
      "response 21: Jeni\n",
      "response 22: Jeni\n",
      "response 23: Jeni\n",
      "response 24: Malave\n",
      "response 25: Malave\n",
      "response 26: Malave\n",
      "response 27: Lorrie Morgan\n",
      "response 28: Lorrie Morgan\n",
      "response 29: Lorrie Morgan\n"
     ]
    }
   ],
   "source": [
    "# classify gap test set zs using gpt3\n",
    "data_path = 'data/gap/gap-test.tsv'\n",
    "num_samples = 10\n",
    "responses = classify_coref_zs(data_path, num_samples)\n",
    "for i, response in enumerate(responses):\n",
    "    print(f'response {i}: {response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coref-mt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/neil/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing documents: {'Eiffel Tower Wiki'}\n",
      "input batch[0]:  ['coref: w | _ The Eiffel Tower ( French : tour Eiffel ) is a wrought - iron lattice tower on the Champ de Mars in Paris , France . It is named after the engineer Gustave Eiffel , whose company designed and built the tower . ** _ Locally nicknamed \" La dame de fer \" ( French for \" Iron Lady \"), it was constructed from 1887 to 1889 as the centerpiece of the 1889 World \\' s Fair . _ Although initially criticised by some of France \\' s leading artists and intellectuals for its design , it has since become a global cultural icon of France and one of the most recognisable structures in the world . _ The Eiffel Tower is the most visited monument with an entrance fee in the world : 6 . 91 million people ascended it in 2015 . _ It was designated a monument historique in 1964 , and was named part of a UNESCO World Heritage Site (\" Paris , Banks of the Seine \") in 1991 .']\n",
      "mt5 output:      ['It ## is named after -> The Eiffel Tower ( French : tour Eiffel ) ## is a wrought ;; the tower ## . ** _ -> It ## is named after ;;']\n",
      "time 0.0034875869750976562, round time/seq : 0.0034949779510498047 total time/seq: 0.0034990310668945312\n",
      "\n",
      "Processing documents: {'Eiffel Tower Wiki'}\n",
      "input batch[0]:  ['coref: w _ [1 The Eiffel Tower ( French : tour Eiffel ) ] is a wrought - iron lattice tower on the Champ de Mars in Paris , France . [1 It ] is named after the engineer Gustave Eiffel , whose company designed and built [1 the tower ] . | _ Locally nicknamed \" La dame de fer \" ( French for \" Iron Lady \"), it was constructed from 1887 to 1889 as the centerpiece of the 1889 World \\' s Fair . ** _ Although initially criticised by some of France \\' s leading artists and intellectuals for its design , it has since become a global cultural icon of France and one of the most recognisable structures in the world . _ The Eiffel Tower is the most visited monument with an entrance fee in the world : 6 . 91 million people ascended it in 2015 . _ It was designated a monument historique in 1964 , and was named part of a UNESCO World Heritage Site (\" Paris , Banks of the Seine \") in 1991 .']\n",
      "mt5 output:      ['it ## was constructed from -> [1 ;;']\n",
      "time 0.0024728775024414062, round time/seq : 0.0024764537811279297 total time/seq: 0.002991795539855957\n",
      "\n",
      "Processing documents: {'Eiffel Tower Wiki'}\n",
      "input batch[0]:  ['coref: w _ [1 The Eiffel Tower ( French : tour Eiffel ) ] is a wrought - iron lattice tower on the Champ de Mars in Paris , France . [1 It ] is named after the engineer Gustave Eiffel , whose company designed and built [1 the tower ] . _ Locally nicknamed \" La dame de fer \" ( French for \" Iron Lady \"), [1 it ] was constructed from 1887 to 1889 as the centerpiece of the 1889 World \\' s Fair . | _ Although initially criticised by some of France \\' s leading artists and intellectuals for its design , it has since become a global cultural icon of France and one of the most recognisable structures in the world . ** _ The Eiffel Tower is the most visited monument with an entrance fee in the world : 6 . 91 million people ascended it in 2015 . _ It was designated a monument historique in 1964 , and was named part of a UNESCO World Heritage Site (\" Paris , Banks of the Seine \") in 1991 .']\n",
      "mt5 output:      [\"its ## design , it -> [1 ;; it ## has since become -> its ## design , it ;; France ' s ## leading artists and -> France ## . [1 It ;; France ## and one of -> France ' s ## leading artists and ;;\"]\n",
      "time 0.0021762847900390625, round time/seq : 0.002179861068725586 total time/seq: 0.00272369384765625\n",
      "\n",
      "Processing documents: {'Eiffel Tower Wiki'}\n",
      "input batch[0]:  ['coref: w _ [1 The Eiffel Tower ( French : tour Eiffel ) ] is a wrought - iron lattice tower on the Champ de Mars in Paris , [2 France ] . [1 It ] is named after the engineer Gustave Eiffel , whose company designed and built [1 the tower ] . _ Locally nicknamed \" La dame de fer \" ( French for \" Iron Lady \"), [1 it ] was constructed from 1887 to 1889 as the centerpiece of the 1889 World \\' s Fair . _ Although initially criticised by some of [2 France \\' s ] leading artists and intellectuals for [1 its ] design , [1 it ] has since become a global cultural icon of [2 France ] and one of the most recognisable structures in the world . | _ The Eiffel Tower is the most visited monument with an entrance fee in the world : 6 . 91 million people ascended it in 2015 . ** _ It was designated a monument historique in 1964 , and was named part of a UNESCO World Heritage Site (\" Paris , Banks of the Seine \") in 1991 .']\n",
      "mt5 output:      ['The Eiffel Tower ## is the most -> [1 ;; it ## in 2015 . -> The Eiffel Tower ## is the most ;; the world ## : 6 . -> the world ## . | _ ;;']\n",
      "time 0.002361297607421875, round time/seq : 0.0023651123046875 total time/seq: 0.002635955810546875\n",
      "\n",
      "Processing documents: {'Eiffel Tower Wiki'}\n",
      "input batch[0]:  ['coref: w _ [1 The Eiffel Tower ( French : tour Eiffel ) ] is a wrought - iron lattice tower on the Champ de Mars in Paris , [2 France ] . [1 It ] is named after the engineer Gustave Eiffel , whose company designed and built [1 the tower ] . _ Locally nicknamed \" La dame de fer \" ( French for \" Iron Lady \"), [1 it ] was constructed from 1887 to 1889 as the centerpiece of the 1889 World \\' s Fair . _ Although initially criticised by some of [2 France \\' s ] leading artists and intellectuals for [1 its ] design , [1 it ] has since become a global cultural icon of [2 France ] and one of the most recognisable structures in [3 the world ] . _ [1 The Eiffel Tower ] is the most visited monument with an entrance fee in [3 the world ] : 6 . 91 million people ascended [1 it ] in 2015 . | _ It was designated a monument historique in 1964 , and was named part of a UNESCO World Heritage Site (\" Paris , Banks of the Seine \") in 1991 . **']\n",
      "mt5 output:      ['It ## was designated a -> [1 ;; Paris ## , Banks of -> Paris , [2 France ## ] . [1 ;;']\n",
      "time 0.001978158950805664, round time/seq : 0.0019812583923339844 total time/seq: 0.002506589889526367\n",
      "\n",
      "predicted clusters with word indexes [[(0, 8), (26, 26), (40, 41), (58, 58), (90, 90), (93, 93), (114, 116), (136, 136), (140, 140)], [(24, 24), (82, 84), (102, 102)], [(111, 112), (127, 128)], [(22, 24), (160, 160)]]\n",
      "[1 The Eiffel Tower ( French : tour Eiffel ) ] is a wrought - iron lattice tower on the Champ de Mars in [4 Paris , [2 France ]] . [1 It ] is named after the engineer Gustave Eiffel , whose company designed and built [1 the tower ] . Locally nicknamed \" La dame de fer \" ( French for \" Iron Lady \"), [1 it ] was constructed from 1887 to 1889 as the centerpiece of the 1889 World ' s Fair . Although initially criticised by some of [2 France ' s ] leading artists and intellectuals for [1 its ] design , [1 it ] has since become a global cultural icon of [2 France ] and one of the most recognisable structures in [3 the world ] . [1 The Eiffel Tower ] is the most visited monument with an entrance fee in [3 the world ] : 6 . 91 million people ascended [1 it ] in 2015 . [1 It ] was designated a monument historique in 1964 , and was named part of a UNESCO World Heritage Site (\" [4 Paris ] , Banks of the Seine \") in 1991 .\n"
     ]
    }
   ],
   "source": [
    "from src.coref_mt5 import *\n",
    "\n",
    "# @title sample document - from wikipedia\n",
    "doc_title = \"Eiffel Tower Wiki\"\n",
    "doc = \"\"\"The Eiffel Tower (French: tour Eiffel) is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower.\n",
    "Locally nicknamed \"La dame de fer\" (French for \"Iron Lady\"), it was constructed from 1887 to 1889 as the centerpiece of the 1889 World's Fair.\n",
    "Although initially criticised by some of France's leading artists and intellectuals for its design, it has since become a global cultural icon of France and one of the most recognisable structures in the world.\n",
    "The Eiffel Tower is the most visited monument with an entrance fee in the world: 6.91 million people ascended it in 2015.\n",
    "It was designated a monument historique in 1964, and was named part of a UNESCO World Heritage Site (\"Paris, Banks of the Seine\") in 1991.\"\"\"\n",
    "\n",
    "emulated_preds = [\n",
    "      [\n",
    "          'It ## is named after -> The Eiffel Tower ( French : tour Eiffel ) ##'\n",
    "          ' is a wrought ;; the tower ## . ** _ -> It ## is named after ;;'\n",
    "      ],\n",
    "      ['it ## was constructed from -> [1 ;;'],\n",
    "      [\n",
    "          'its ## design , it -> [1 ;; it ## has since become -> its ## design'\n",
    "          \" , it ;; France ' s ## leading artists and -> France ## . [1 It ;;\"\n",
    "          \" France ## and one of -> France ' s ## leading artists and ;;\"\n",
    "      ],\n",
    "      [\n",
    "          'The Eiffel Tower ## is the most -> [1 ;; it ## in 2015 . -> The'\n",
    "          ' Eiffel Tower ## is the most ;; the world ## : 6 . -> the world ## .'\n",
    "          ' | _ ;;'\n",
    "      ],\n",
    "      [\n",
    "          'It ## was designated a -> [1 ;; Paris ## , Banks of -> Paris , [2'\n",
    "          ' France ## ] . [1 ;;'\n",
    "      ],\n",
    "]\n",
    "\n",
    "# predict coref using mt5\n",
    "states_dict = pred_cr_mt5(doc, doc_title, emulate_preds=True, emulated_preds=emulated_preds, debug=True, expand_only=False)\n",
    "\n",
    "# print coref result as annotated text\n",
    "annotate_cr(states_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/12/2023 14:50:44 - INFO - \t missing_keys: []\n",
      "10/12/2023 14:50:44 - INFO - \t unexpected_keys: []\n",
      "10/12/2023 14:50:44 - INFO - \t mismatched_keys: []\n",
      "10/12/2023 14:50:44 - INFO - \t error_msgs: []\n",
      "10/12/2023 14:50:44 - INFO - \t Model Parameters: 590.0M, Transformer: 434.6M, Coref head: 155.4M\n",
      "10/12/2023 14:50:44 - INFO - \t Tokenize 2000 inputs...\n",
      "Map: 100%|██████████| 2000/2000 [00:07<00:00, 270.48 examples/s]\n",
      "10/12/2023 14:50:51 - INFO - \t ***** Running Inference on 2000 texts *****\n",
      "Inference: 100%|██████████| 2000/2000 [00:42<00:00, 47.53it/s]\n",
      "10/12/2023 14:51:34 - INFO - \t Tokenize 2000 inputs...\n",
      "Map: 100%|██████████| 2000/2000 [00:06<00:00, 314.91 examples/s]\n",
      "10/12/2023 14:51:40 - INFO - \t ***** Running Inference on 2000 texts *****\n",
      "Inference: 100%|██████████| 2000/2000 [00:41<00:00, 47.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting labels for 2000 samples using LingMessCoref...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:00, 13341.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "evaluating metrics on None for lmcoref on GAP test...\n",
      "acc: 0.707\n",
      "f1: 0.674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# classify gap test set zs using fcoref\n",
    "data_path = 'data/gap/gap-test.tsv'  # path to gap test set\n",
    "num_samples = None # number of samples to classify\n",
    "model_name = 'lmcoref'  # either 'fcoref' or 'lmcoref'\n",
    "# init fcoref classifier\n",
    "fcr_classifier = FCorefClassifier(model_name, data_path, num_samples)\n",
    "# get cluster preds\n",
    "cluster_preds = fcr_classifier.pred_cr_clusters()\n",
    "# get label preds\n",
    "labels, preds = fcr_classifier.pred_cr_labels(verbose=False)\n",
    "\n",
    "# eval \n",
    "metrics = ['acc', 'f1'] # metrics to eval\n",
    "res_file_path = None # path to save results\n",
    "print(f'evaluating metrics on {num_samples} for {model_name} on GAP test...')\n",
    "eval_res = eval_preds(labels, preds, metrics)\n",
    "for metric, val in eval_res.items():\n",
    "    print(f'{metric}: {val:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train fastcoref on GAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create gap clusters\n",
    "data_path = 'data/gap/gap-development.tsv'\n",
    "output_path = 'data/gap/gap-development-with-clusters.jsonlines'\n",
    "num_samples = None\n",
    "# convert_gap_to_jsonlines(data_path, output_path, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:53853lju) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">zesty-sound-4</strong> at: <a href='https://wandb.ai/abhinav-neil/test-trainer/runs/53853lju' target=\"_blank\">https://wandb.ai/abhinav-neil/test-trainer/runs/53853lju</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231012_162848-53853lju/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:53853lju). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/neil/dl4nlp-pr/wandb/run-20231012_163503-u69nazte</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/abhinav-neil/test-trainer/runs/u69nazte' target=\"_blank\">spring-resonance-5</a></strong> to <a href='https://wandb.ai/abhinav-neil/test-trainer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/abhinav-neil/test-trainer' target=\"_blank\">https://wandb.ai/abhinav-neil/test-trainer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/abhinav-neil/test-trainer/runs/u69nazte' target=\"_blank\">https://wandb.ai/abhinav-neil/test-trainer/runs/u69nazte</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/12/2023 16:35:15 - INFO - \t Loading FCoref model with underlying transformer distilroberta-base\n",
      "10/12/2023 16:35:17 - INFO - \t FCoref Parameters: 90.5M, Transformer: 82.1M, Coref head: 8.4M\n",
      "Generating train split: 2000 examples [00:00, 16570.42 examples/s]\n",
      "Map:  14%|█▎        | 272/2000 [00:03<00:22, 76.46 examples/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'start'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/neil/dl4nlp-pr/main.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bneil-vm5.us-west4-b.ellogon-366011/home/neil/dl4nlp-pr/main.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfastcoref\u001b[39;00m \u001b[39mimport\u001b[39;00m TrainingArgs, CorefTrainer\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bneil-vm5.us-west4-b.ellogon-366011/home/neil/dl4nlp-pr/main.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m args \u001b[39m=\u001b[39m TrainingArgs(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bneil-vm5.us-west4-b.ellogon-366011/home/neil/dl4nlp-pr/main.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     output_dir\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtest-trainer\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bneil-vm5.us-west4-b.ellogon-366011/home/neil/dl4nlp-pr/main.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     overwrite_output_dir\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneil-vm5.us-west4-b.ellogon-366011/home/neil/dl4nlp-pr/main.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     eval_steps\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneil-vm5.us-west4-b.ellogon-366011/home/neil/dl4nlp-pr/main.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m )   \u001b[39m# you can control other arguments such as learning head and others.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bneil-vm5.us-west4-b.ellogon-366011/home/neil/dl4nlp-pr/main.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m trainer \u001b[39m=\u001b[39m CorefTrainer(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneil-vm5.us-west4-b.ellogon-366011/home/neil/dl4nlp-pr/main.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneil-vm5.us-west4-b.ellogon-366011/home/neil/dl4nlp-pr/main.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     train_file\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdata/gap/gap-development-with-clusters.jsonlines\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneil-vm5.us-west4-b.ellogon-366011/home/neil/dl4nlp-pr/main.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m# dev_file='data/gap/gap-validation-with-clusters.jsonlines',\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneil-vm5.us-west4-b.ellogon-366011/home/neil/dl4nlp-pr/main.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     test_file\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdata/gap/gap-test-with-clusters.jsonlines\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneil-vm5.us-west4-b.ellogon-366011/home/neil/dl4nlp-pr/main.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# nlp=nlp # optional, for custom nlp class from spacy\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneil-vm5.us-west4-b.ellogon-366011/home/neil/dl4nlp-pr/main.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneil-vm5.us-west4-b.ellogon-366011/home/neil/dl4nlp-pr/main.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m trainer\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneil-vm5.us-west4-b.ellogon-366011/home/neil/dl4nlp-pr/main.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m trainer\u001b[39m.\u001b[39mevaluate(test\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/envs/dl4nlp-pr/lib/python3.11/site-packages/fastcoref/trainer.py:118\u001b[0m, in \u001b[0;36mCorefTrainer.__init__\u001b[0;34m(self, args, train_file, dev_file, test_file, nlp)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_dataset, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_sampler \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m test_file \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_dataset, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_sampler \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_sampler(test_file)\n\u001b[1;32m    120\u001b[0m set_seed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs)\n",
      "File \u001b[0;32m/opt/conda/envs/dl4nlp-pr/lib/python3.11/site-packages/fastcoref/trainer.py:123\u001b[0m, in \u001b[0;36mCorefTrainer._get_sampler\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_sampler\u001b[39m(\u001b[39mself\u001b[39m, file):\n\u001b[0;32m--> 123\u001b[0m     dataset \u001b[39m=\u001b[39m coref_dataset\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m    124\u001b[0m         file\u001b[39m=\u001b[39;49mfile, tokenizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer, nlp\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnlp\n\u001b[1;32m    125\u001b[0m     )\n\u001b[1;32m    126\u001b[0m     sampler \u001b[39m=\u001b[39m DynamicBatchSampler(\n\u001b[1;32m    127\u001b[0m         dataset\u001b[39m=\u001b[39mdataset,\n\u001b[1;32m    128\u001b[0m         collator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollator,\n\u001b[1;32m    129\u001b[0m         max_tokens\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mmax_tokens_in_batch,\n\u001b[1;32m    130\u001b[0m         max_segment_len\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mmax_segment_len\n\u001b[1;32m    131\u001b[0m     )\n\u001b[1;32m    133\u001b[0m     \u001b[39mreturn\u001b[39;00m dataset, sampler\n",
      "File \u001b[0;32m/opt/conda/envs/dl4nlp-pr/lib/python3.11/site-packages/fastcoref/utilities/coref_dataset.py:143\u001b[0m, in \u001b[0;36mcreate\u001b[0;34m(file, tokenizer, nlp)\u001b[0m\n\u001b[1;32m    132\u001b[0m features \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39mFeatures(\n\u001b[1;32m    133\u001b[0m     {\n\u001b[1;32m    134\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoc_key\u001b[39m\u001b[39m\"\u001b[39m: Value(\u001b[39m\"\u001b[39m\u001b[39mstring\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m     }\n\u001b[1;32m    140\u001b[0m )\n\u001b[1;32m    142\u001b[0m dataset \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39mfrom_generator(read_jsonlines, features\u001b[39m=\u001b[39mfeatures, gen_kwargs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mfile\u001b[39m\u001b[39m'\u001b[39m: file})\n\u001b[0;32m--> 143\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmap(\n\u001b[1;32m    144\u001b[0m     encode, batched\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    145\u001b[0m     fn_kwargs\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mtokenizer\u001b[39;49m\u001b[39m'\u001b[39;49m: tokenizer, \u001b[39m'\u001b[39;49m\u001b[39mnlp\u001b[39;49m\u001b[39m'\u001b[39;49m: nlp},\n\u001b[1;32m    146\u001b[0m     load_from_cache_file\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    147\u001b[0m )\n\u001b[1;32m    149\u001b[0m \u001b[39mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m/opt/conda/envs/dl4nlp-pr/lib/python3.11/site-packages/datasets/arrow_dataset.py:592\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    591\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 592\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    593\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    594\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/dl4nlp-pr/lib/python3.11/site-packages/datasets/arrow_dataset.py:557\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    551\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    552\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    553\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    554\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    555\u001b[0m }\n\u001b[1;32m    556\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    558\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    559\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/dl4nlp-pr/lib/python3.11/site-packages/datasets/arrow_dataset.py:3097\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3090\u001b[0m \u001b[39mif\u001b[39;00m transformed_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3091\u001b[0m     \u001b[39mwith\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(\n\u001b[1;32m   3092\u001b[0m         disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled(),\n\u001b[1;32m   3093\u001b[0m         unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   3094\u001b[0m         total\u001b[39m=\u001b[39mpbar_total,\n\u001b[1;32m   3095\u001b[0m         desc\u001b[39m=\u001b[39mdesc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMap\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   3096\u001b[0m     ) \u001b[39mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3097\u001b[0m         \u001b[39mfor\u001b[39;00m rank, done, content \u001b[39min\u001b[39;00m Dataset\u001b[39m.\u001b[39m_map_single(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3098\u001b[0m             \u001b[39mif\u001b[39;00m done:\n\u001b[1;32m   3099\u001b[0m                 shards_done \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/dl4nlp-pr/lib/python3.11/site-packages/datasets/arrow_dataset.py:3450\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3448\u001b[0m _time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   3449\u001b[0m \u001b[39mfor\u001b[39;00m i, example \u001b[39min\u001b[39;00m shard_iterable:\n\u001b[0;32m-> 3450\u001b[0m     example \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(example, i, offset\u001b[39m=\u001b[39;49moffset)\n\u001b[1;32m   3451\u001b[0m     \u001b[39mif\u001b[39;00m update_data:\n\u001b[1;32m   3452\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/dl4nlp-pr/lib/python3.11/site-packages/datasets/arrow_dataset.py:3353\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3351\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[1;32m   3352\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[0;32m-> 3353\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[1;32m   3354\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3355\u001b[0m     processed_inputs \u001b[39m=\u001b[39m {\n\u001b[1;32m   3356\u001b[0m         k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mkeys_to_format\n\u001b[1;32m   3357\u001b[0m     }\n",
      "File \u001b[0;32m/opt/conda/envs/dl4nlp-pr/lib/python3.11/site-packages/fastcoref/utilities/coref_dataset.py:72\u001b[0m, in \u001b[0;36mencode\u001b[0;34m(example, tokenizer, nlp)\u001b[0m\n\u001b[1;32m     69\u001b[0m spacy_doc \u001b[39m=\u001b[39m nlp(example[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     70\u001b[0m example[\u001b[39m'\u001b[39m\u001b[39mtokens\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [tok\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m tok \u001b[39min\u001b[39;00m spacy_doc]\n\u001b[0;32m---> 72\u001b[0m new_clusters \u001b[39m=\u001b[39m [[(spacy_doc\u001b[39m.\u001b[39;49mchar_span(start, end)\u001b[39m.\u001b[39;49mstart,\n\u001b[1;32m     73\u001b[0m                   spacy_doc\u001b[39m.\u001b[39;49mchar_span(start, end)\u001b[39m.\u001b[39;49mend \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     74\u001b[0m                  \u001b[39mfor\u001b[39;49;00m start, end \u001b[39min\u001b[39;49;00m cluster] \u001b[39mfor\u001b[39;49;00m cluster \u001b[39min\u001b[39;49;00m clusters]\n\u001b[1;32m     75\u001b[0m \u001b[39m# verify alignment\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[39mfor\u001b[39;00m cluster, new_cluster \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(clusters, new_clusters):\n",
      "File \u001b[0;32m/opt/conda/envs/dl4nlp-pr/lib/python3.11/site-packages/fastcoref/utilities/coref_dataset.py:72\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     69\u001b[0m spacy_doc \u001b[39m=\u001b[39m nlp(example[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     70\u001b[0m example[\u001b[39m'\u001b[39m\u001b[39mtokens\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [tok\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m tok \u001b[39min\u001b[39;00m spacy_doc]\n\u001b[0;32m---> 72\u001b[0m new_clusters \u001b[39m=\u001b[39m [[(spacy_doc\u001b[39m.\u001b[39;49mchar_span(start, end)\u001b[39m.\u001b[39;49mstart,\n\u001b[1;32m     73\u001b[0m                   spacy_doc\u001b[39m.\u001b[39;49mchar_span(start, end)\u001b[39m.\u001b[39;49mend \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     74\u001b[0m                  \u001b[39mfor\u001b[39;49;00m start, end \u001b[39min\u001b[39;49;00m cluster] \u001b[39mfor\u001b[39;00m cluster \u001b[39min\u001b[39;00m clusters]\n\u001b[1;32m     75\u001b[0m \u001b[39m# verify alignment\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[39mfor\u001b[39;00m cluster, new_cluster \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(clusters, new_clusters):\n",
      "File \u001b[0;32m/opt/conda/envs/dl4nlp-pr/lib/python3.11/site-packages/fastcoref/utilities/coref_dataset.py:72\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     69\u001b[0m spacy_doc \u001b[39m=\u001b[39m nlp(example[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     70\u001b[0m example[\u001b[39m'\u001b[39m\u001b[39mtokens\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [tok\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m tok \u001b[39min\u001b[39;00m spacy_doc]\n\u001b[0;32m---> 72\u001b[0m new_clusters \u001b[39m=\u001b[39m [[(spacy_doc\u001b[39m.\u001b[39;49mchar_span(start, end)\u001b[39m.\u001b[39;49mstart,\n\u001b[1;32m     73\u001b[0m                   spacy_doc\u001b[39m.\u001b[39mchar_span(start, end)\u001b[39m.\u001b[39mend \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     74\u001b[0m                  \u001b[39mfor\u001b[39;00m start, end \u001b[39min\u001b[39;00m cluster] \u001b[39mfor\u001b[39;00m cluster \u001b[39min\u001b[39;00m clusters]\n\u001b[1;32m     75\u001b[0m \u001b[39m# verify alignment\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[39mfor\u001b[39;00m cluster, new_cluster \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(clusters, new_clusters):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'start'"
     ]
    }
   ],
   "source": [
    "from fastcoref import TrainingArgs, CorefTrainer\n",
    "\n",
    "args = TrainingArgs(\n",
    "    output_dir='test-trainer',\n",
    "    overwrite_output_dir=True,\n",
    "    model_name_or_path='distilroberta-base',\n",
    "    device=device,\n",
    "    epochs=100,\n",
    "    logging_steps=100,\n",
    "    eval_steps=100\n",
    ")   # you can control other arguments such as learning head and others.\n",
    "\n",
    "trainer = CorefTrainer(\n",
    "    args=args,\n",
    "    train_file='data/gap/gap-development-with-clusters.jsonlines', \n",
    "    # dev_file='data/gap/gap-validation-with-clusters.jsonlines',\n",
    "    test_file='data/gap/gap-test-with-clusters.jsonlines',\n",
    "    # nlp=nlp # optional, for custom nlp class from spacy\n",
    ")\n",
    "trainer.train()\n",
    "trainer.evaluate(test=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4nlp-pr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
